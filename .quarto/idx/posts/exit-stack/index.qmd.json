{"title":"Exit stack to the rescue","markdown":{"yaml":{"title":"Exit stack to the rescue","description":"How to chain resource managers in an elegant way.","author":"bwrob","date":"2024-05-12","date-modified":"2024-08-30","categories":["Pythonic Distractions","Context Managers"],"image":"flowchart.png","format-links":["html"]},"headingText":"Working with risk managment systems","containsRefs":false,"markdown":"\n\n\nAs a quantitative finance professional you'll often find yourself with risk management systems (RMS).\nRMS's are extensive frameworks that let you properly define a book (portfolio) of your financial transactions and run varia of pricing and risk analysis on it.\nFor big financial players, like investment banks, the RMS will be internal proprietary codbase that is run in-house.\nFor smaller enterprises or second-line reporting it's not feasable to tackle creating such vast infrastructure.\nHence, where there's a need, someone will try to make money on it. This leads us to third-party (or vendor) RMS, of which there are plenty (ex. Murex, Acadia).\n\nWorking with vendor RMS, especially one that covers computations for you, entails juggling multiple resources to obtain your risk metrics.\nDefining OTC products, benchmarks, portfolios, and running risk analysis can involve numerous API calls, each requiring proper setup and cleanup.\nThis can lead to messy code and potential errors or performance bottlenecks if resources aren't handled correctly.\n\nThankfully, Python provides a powerful concept called context managers (**CM**) that streamline resource managment.\nTrue to the language's 'batteries included' philosophy, there's also a `contextlib` library that contains variety of tools for easing up your work with CMs.\nToday we'll look at a (mock-up) usage of `ExitStack` class in real-life scenario of running risk analysis on RMS.\nIf you need a refresher on CMs, check out this [tutorial](https://realpython.com/python-with-statement/) by RealPython.\n\n## Setting the stage\n\nTo run an analysis, the RMS first needs to know what our positions are.\nIn case of tradable assets it's simple --- we provide a market identifier and how much of the instrument we are holding.\nWhat do we do if we have some bespoke agreement with specific counterparty (an over-the-counter transaction)?\nWe will need to define it from scratch in the RMS using data from the term sheet (assuming this kind of agreement is covered).\n\nNext, we need to specify the risk metrics we want to calculate --- define the analysis scope.\nLet's say we hold some equity options and we are intertested in their deltas and beta exposures.\nThe betas are defined with respect to some benchmark --- ex. portfolio holding 1 stock in US500 ETF. So we define the benchmark and link it to our analysis.\n\nFinally --- once portfolio and analysis are defined in RMS --- we call the API to start the calculation and respond with results.\nThis is the control flow we execute to get to this point:\n\n```{mermaid}\nflowchart LR\n  A[OTC Products] --> B[Portfolio]\n  B --> C{Analysis Run}\n  D[Benchmarks] --> E[Analysis Definition]\n  E --> C\n  C --> F(Results)\n```\n\nIf we know we're never going to use all of the resources, we should clean up the server artifacts after receving the results. So for each resource we should have a CM.\n\n### Mock functions\n\nThe setup described above comes from a real-life situation I worked through. I can't show you the actual API usage or data (or even the name of RMS itself), so we need to define some mocker functions. Mocks like this are actually not an uncommon thing --- such approach is prevalent in testing API client code. In our case it would look like this:\n\n```{python}\nfrom enum import StrEnum\nfrom uuid import uuid4\n\n\nclass MockObject(StrEnum):\n    \"\"\"Types of mock objects.\"\"\"\n\n    ANALYSIS = \"analysis\"\n    BENCHMARK = \"benchmark\"\n    OTC_PRODUCTS = \"otc_products\"\n    PORTFOLIO = \"portfolio\"\n\n\ndef mock_object(object_type: MockObject) -> str:\n    \"\"\"Mock a UUID for a given object type.\n\n    Args:\n        object_type: Type of object.\n    \"\"\"\n    return f\"{object_type}_{uuid4()}\"\n\n\ndef mock_preparation(object_type: MockObject, **kwargs) -> None:\n    \"\"\"Mock preparation of an object.\n\n    Args:\n        object_type: Type of object.\n    \"\"\"\n    print(f\"Preparing {object_type}\" + (f\" using {kwargs}\" if kwargs else \".\"))\n\n\ndef mock_clean_up(object_uuid: str) -> None:\n    \"\"\"Mock clean up of an object.\n\n    Args:\n        object_uuid: Uuid of the object.\n    \"\"\"\n    print(f\"Cleaning up after {object_uuid}.\")\n```\n\nFor each of the four types of resources we mock the preparation, object (ex. API response, some id of definition on server) and the clean up process.\n\n### Context managers\n\nEasiest way to define a CM is through `contextlib.contextmanager` decorator. To use it, you need a function that returns a generator. Code executed on enter should come before `yield` statement and the one for the exit afterwards. The generator yields the result of the CM (ex. handle to an opened file), the `y` in `with x(*args) as y:`.\n\n```{python}\nfrom contextlib import contextmanager\nfrom typing import Generator\n\n@contextmanager\ndef analysis(\n    *,\n    benchmark_uuid: str,\n) -> Generator[str, None, None]:\n    \"\"\"Mock definition of an analysis.\n\n    Example: equity delta and correlation with benchmark.\n\n    Args:\n        benchmark_uuid: Uuid of the benchmark.\n    \"\"\"\n    mock_preparation(\n        MockObject.ANALYSIS,\n        benchmark_name=benchmark_uuid,\n    )\n    analysis_uuid = mock_object(MockObject.ANALYSIS)\n    yield analysis_uuid\n    mock_clean_up(analysis_uuid)\n```\n\nModern approach to Python development leans heavily towards type annotations. Dynamical typing is powerful but can lead to unwieldy code. To properly annotate the `analysis` function we need to import `Generator` from `typing` module. Remember, the `@contextmanager` decorator takes the function and turns it into CM --- a class with `__enter__` and `__exit__` methods. The `Generator` needs three inputs but in our case only the first one is important --- `YieldType`, here `str` ([see](https://docs.python.org/3/library/typing.html#typing.Generator) for more).\n\nWith this done implementing the 3 remaining CMs is easy, just remember our flow chart.\n\n```{python}\n@contextmanager\ndef benchmark() -> Generator[str, None, None]:\n    \"\"\"Mock definition of a benchmark.\n\n    Args:\n        otc_products_uuid: Uuid of the otc products.\n    \"\"\"\n    mock_preparation(\n        MockObject.BENCHMARK,\n    )\n    benchmark_uuid = mock_object(MockObject.BENCHMARK)\n    yield benchmark_uuid\n    mock_clean_up(benchmark_uuid)\n\n\n@contextmanager\ndef otc_products() -> Generator[str, None, None]:\n    \"\"\"Mock definition of an otc products.\n\n    Args:\n        otc_products_uuid: Uuid of the otc products.\n    \"\"\"\n    mock_preparation(MockObject.OTC_PRODUCTS)\n    otcs_uuid = mock_object(MockObject.OTC_PRODUCTS)\n    yield otcs_uuid\n    mock_clean_up(otcs_uuid)\n\n\n@contextmanager\ndef portfolio(\n    *,\n    portfolio_name: str,\n    otc_products_uuid: str,\n) -> Generator[str, None, None]:\n    \"\"\"Mock definition of a portfolio.\n\n    Args:\n        otc_products_uuid: Uuid of the otc products.\n    \"\"\"\n    mock_preparation(\n        MockObject.PORTFOLIO,\n        portfolio_name=portfolio_name,\n        otc_products_uuid=otc_products_uuid,\n    )\n    portfolio_uuid = mock_object(MockObject.PORTFOLIO)\n    yield portfolio_uuid\n    mock_clean_up(portfolio_uuid)\n```\n\n### Analysis results\n\nNo stress or complexity here, to run the analysis we need to specify which analysis to run on which portfolio.\n\n```{python}\nimport pandas as pd\n\ndef analysis_results(\n    *,\n    analysis_uuid: str,\n    portfolio_uuid: str,\n) -> pd.DataFrame:\n    \"\"\"Mock running the analysis on a given portfolio.\n\n    Returns empty dataframe.\n\n    Args:\n        analysis_uuid: Uuid of the analysis.\n        portfolio_uuid: Uuid of the portfolio.\n    \"\"\"\n    print(f\"Running analysis {analysis_uuid} on portfolio {portfolio_uuid}.\")\n    return pd.DataFrame()\n```\n\n##\n\nFinally, we can run some (mock) risk analysis!\n\n### Using contexts directly\n\nFirst, we use the managers directly through `with` clause, remembering the dependencies from our flow chart.\n\n```{python}\nPORTFOLIO = \"portfolio_1\"\n\ndef run_analysis() -> pd.DataFrame:\n    \"\"\"Mock running the analysis using with clauses.\"\"\"\n    with otc_products() as otc_uuid:\n        with benchmark() as benchmark_uuid:\n            with portfolio(\n                portfolio_name=PORTFOLIO,\n                otc_products_uuid=otc_uuid,\n            ) as portfolio_uuid:\n                with analysis(\n                    benchmark_uuid=benchmark_uuid,\n                ) as analysis_uuid:\n                    results = analysis_results(\n                        analysis_uuid=analysis_uuid,\n                        portfolio_uuid=portfolio_uuid,\n                    )\n    return results\n```\n\nThis is terrible! I am already getting lost, needed few tries to get it right. We ended up with **6** levels of indentation, the code is confusing, the flow is obtuse. Let's run it either way, to see if at least works.\n\n```{python}\ndef print_title(title: str) -> None:\n    \"\"\"Print a title padded, surrounded by dashes and empty lines.\"\"\"\n    print(\"\\n\" + title.center(60, \"-\") + \"\\n\")\n\nprint_title(\"Running analysis.\")\nrun_analysis()\n```\n\nGreat, the behaviour is as expected, everything is cleaned after nicely. We achieved the goal but the code is unmaintainable. Looks like a subject of the joke *\"good code makes your job safe for a day, but terrible code in production makes it safe for a lifetime\"*. Being reckless and with no regard to job security as we are, we'll fix it.\n\n*I can clearly recall the most unamanagable and unreadable code I've seen in my career and the culprit was fired in the end. Different reasons, long time later, but still. So the joke is just a joke, don't rely on a bad code as your job insurance.*\n\n## The ExitStack\n\nHere comes in the MVP --- `ExitStack` from `contextlib`, made for streamlining complex context managment situationships. Conceptually it's just a First-In-Last-Out (FILO) stack. You put CMs on top, one by one. When CM is pushed to stack, its `__enter__` method is called and you can intercept the result. ExitStack is a CM itself, it's `__exit__` method is just calling the exits of CMs in reverse order.\n\n```{mermaid}\nflowchart LR\n    A(Enter CM A) ---> B(Enter CM B)\n    B ---> C(Enter CM C)\n    C ---> D[Do stuff]\n    D ---> E(Exit CM C)\n    E ---> F(Exit CM B)\n    F ---> G(Exit CM A)\n    A -.- G\n    B -.- F\n    C -.- E\n\n```\n\nSo the flow is exactly the same as in our first attempt. Let's try it!\n\n```{python}\nfrom contextlib import ExitStack\n\ndef run_analysis_with_exit_stack() -> None:\n    \"\"\"Mock running the analysis using exit stack.\"\"\"\n    with ExitStack() as stack:\n        otc_uuid = stack.enter_context(otc_products())\n        benchmark_uuid = stack.enter_context(benchmark())\n        portfolio_uuid = stack.enter_context(\n            portfolio(\n                portfolio_name=PORTFOLIO,\n                otc_products_uuid=otc_uuid,\n            )\n        )\n        analysis_uuid = stack.enter_context(\n            analysis(\n                benchmark_uuid=benchmark_uuid,\n            )\n        )\n        results = analysis_results(\n            analysis_uuid=analysis_uuid,\n            portfolio_uuid=portfolio_uuid,\n        )\n```\n\nThat's amazing (if the approach works)! In our code we end up with only single `with` clause and the outputs of CMs are defined just like the regular variables. We just need to wrap the CM calls in `stack.enter_context` method that pushes each CM to the stack.\n\n```{python}\nprint_title(\"Running analysis with exit stack.\")\nrun_analysis_with_exit_stack()\n\n```\n\nIt works as well! We also get a package of benefits for free.\n\n### Disabling the clean up\n\nWorking with API is tricky and debugging could be a painful experience. If we notice something iffy with the results we are reciving, it could be due to a bug at any of the stages. In such case disabling the artifact clean up and examining them is a good way to investigate. How do we do that? Comment out the exit code in our resource CMs? Nope, now we know better. With exit stack approach we just need to clean up the stack before exiting its context.\n\n```{python}\ndef run_analysis_with_exit_stack(\n    clean_up: bool = True,\n) -> None:\n    \"\"\"Mock running the analysis using exit stack.\n\n    Args:\n        clean_up: Whether to clean up after the objects.\n    \"\"\"\n\n    with ExitStack() as stack:\n        otc_uuid = stack.enter_context(otc_products())\n        benchmark_uuid = stack.enter_context(benchmark())\n        portfolio_uuid = stack.enter_context(\n            portfolio(\n                portfolio_name=PORTFOLIO,\n                otc_products_uuid=otc_uuid,\n            )\n        )\n        analysis_uuid = stack.enter_context(\n            analysis(\n                benchmark_uuid=benchmark_uuid,\n            )\n        )\n        results = analysis_results(\n            analysis_uuid=analysis_uuid,\n            portfolio_uuid=portfolio_uuid,\n        )\n\n        if not clean_up:\n            _ = stack.pop_all()\n    return results\n```\n\nThe `_ = some_function()` is a Pythonic way of disregarding outputs of `some_function`. Method `pop_all` actually moves the stack contents to a new stack, but we don't care about that. We just want to get rid of them from our current one.\n\n```{python}\nprint_title(\"Running analysis with exit stack and no clean up.\")\nrun_analysis_with_exit_stack(clean_up=False)\n```\n\n### Multiple portfolios\n\nBenefit #2 --- what do we do if we have multiple managers and many portfolios to re-run for? Or --- outside of the example scope --- we want to held multiple files open at the same time? Easy, we just push to the stack in a loop or a list comprehension.\n\n```{python}\nPORTFOLIOS = [\"portfolio_1\", \"portfolio_2\", \"portfolio_3\"]\n\ndef run_analysis_with_exit_stack(clean_up: bool = True):\n    \"\"\"Mock running the analysis for multiple portfolios using exit stack.\n\n    Args:\n        clean_up: Whether to clean up after the objects.\n    \"\"\"\n    with ExitStack() as stack:\n        otc_uuid = stack.enter_context(otc_products())\n        benchmark_uuid = stack.enter_context(benchmark())\n        portfolio_uuids = [\n            stack.enter_context(\n                portfolio(\n                    portfolio_name=portfolio_name,\n                    otc_products_uuid=otc_uuid,\n                )\n            )\n            for portfolio_name in PORTFOLIOS\n        ]\n        analysis_uuid = stack.enter_context(\n            analysis(\n                benchmark_uuid=benchmark_uuid,\n            )\n        )\n        result_parts = [\n            analysis_results(\n                analysis_uuid=analysis_uuid,\n                portfolio_uuid=portfolio_uuid,\n            )\n            for portfolio_uuid in portfolio_uuids\n        ]\n        results = pd.concat(result_parts)\n\n        if not clean_up:\n            _ = stack.pop_all()\n    return results\n\nprint_title(\"Running analysis with exit stack on multiple portfolios.\")\nrun_analysis_with_exit_stack(clean_up=True)\n```\n\n## Conclusion\n\nToday we've learnt a new Python tool and seen an example of how quantitative developer might set up risk reporting job on vendor RMS. Sound like a very niche and unlikely situation for you? Maybe. But the moral here is to go and explore the Python standard library. Without using any additional packages we improved readability and flexibility of our initial attempt. Python really has *'batteries included'*, [see](https://docs.python.org/3/library/index.html) for yourself!\n\n::: callout-note\nDownload the whole code [here](../../scripts/exit_stack.py).\n:::\n","srcMarkdownNoYaml":"\n\n## Working with risk managment systems\n\nAs a quantitative finance professional you'll often find yourself with risk management systems (RMS).\nRMS's are extensive frameworks that let you properly define a book (portfolio) of your financial transactions and run varia of pricing and risk analysis on it.\nFor big financial players, like investment banks, the RMS will be internal proprietary codbase that is run in-house.\nFor smaller enterprises or second-line reporting it's not feasable to tackle creating such vast infrastructure.\nHence, where there's a need, someone will try to make money on it. This leads us to third-party (or vendor) RMS, of which there are plenty (ex. Murex, Acadia).\n\nWorking with vendor RMS, especially one that covers computations for you, entails juggling multiple resources to obtain your risk metrics.\nDefining OTC products, benchmarks, portfolios, and running risk analysis can involve numerous API calls, each requiring proper setup and cleanup.\nThis can lead to messy code and potential errors or performance bottlenecks if resources aren't handled correctly.\n\nThankfully, Python provides a powerful concept called context managers (**CM**) that streamline resource managment.\nTrue to the language's 'batteries included' philosophy, there's also a `contextlib` library that contains variety of tools for easing up your work with CMs.\nToday we'll look at a (mock-up) usage of `ExitStack` class in real-life scenario of running risk analysis on RMS.\nIf you need a refresher on CMs, check out this [tutorial](https://realpython.com/python-with-statement/) by RealPython.\n\n## Setting the stage\n\nTo run an analysis, the RMS first needs to know what our positions are.\nIn case of tradable assets it's simple --- we provide a market identifier and how much of the instrument we are holding.\nWhat do we do if we have some bespoke agreement with specific counterparty (an over-the-counter transaction)?\nWe will need to define it from scratch in the RMS using data from the term sheet (assuming this kind of agreement is covered).\n\nNext, we need to specify the risk metrics we want to calculate --- define the analysis scope.\nLet's say we hold some equity options and we are intertested in their deltas and beta exposures.\nThe betas are defined with respect to some benchmark --- ex. portfolio holding 1 stock in US500 ETF. So we define the benchmark and link it to our analysis.\n\nFinally --- once portfolio and analysis are defined in RMS --- we call the API to start the calculation and respond with results.\nThis is the control flow we execute to get to this point:\n\n```{mermaid}\nflowchart LR\n  A[OTC Products] --> B[Portfolio]\n  B --> C{Analysis Run}\n  D[Benchmarks] --> E[Analysis Definition]\n  E --> C\n  C --> F(Results)\n```\n\nIf we know we're never going to use all of the resources, we should clean up the server artifacts after receving the results. So for each resource we should have a CM.\n\n### Mock functions\n\nThe setup described above comes from a real-life situation I worked through. I can't show you the actual API usage or data (or even the name of RMS itself), so we need to define some mocker functions. Mocks like this are actually not an uncommon thing --- such approach is prevalent in testing API client code. In our case it would look like this:\n\n```{python}\nfrom enum import StrEnum\nfrom uuid import uuid4\n\n\nclass MockObject(StrEnum):\n    \"\"\"Types of mock objects.\"\"\"\n\n    ANALYSIS = \"analysis\"\n    BENCHMARK = \"benchmark\"\n    OTC_PRODUCTS = \"otc_products\"\n    PORTFOLIO = \"portfolio\"\n\n\ndef mock_object(object_type: MockObject) -> str:\n    \"\"\"Mock a UUID for a given object type.\n\n    Args:\n        object_type: Type of object.\n    \"\"\"\n    return f\"{object_type}_{uuid4()}\"\n\n\ndef mock_preparation(object_type: MockObject, **kwargs) -> None:\n    \"\"\"Mock preparation of an object.\n\n    Args:\n        object_type: Type of object.\n    \"\"\"\n    print(f\"Preparing {object_type}\" + (f\" using {kwargs}\" if kwargs else \".\"))\n\n\ndef mock_clean_up(object_uuid: str) -> None:\n    \"\"\"Mock clean up of an object.\n\n    Args:\n        object_uuid: Uuid of the object.\n    \"\"\"\n    print(f\"Cleaning up after {object_uuid}.\")\n```\n\nFor each of the four types of resources we mock the preparation, object (ex. API response, some id of definition on server) and the clean up process.\n\n### Context managers\n\nEasiest way to define a CM is through `contextlib.contextmanager` decorator. To use it, you need a function that returns a generator. Code executed on enter should come before `yield` statement and the one for the exit afterwards. The generator yields the result of the CM (ex. handle to an opened file), the `y` in `with x(*args) as y:`.\n\n```{python}\nfrom contextlib import contextmanager\nfrom typing import Generator\n\n@contextmanager\ndef analysis(\n    *,\n    benchmark_uuid: str,\n) -> Generator[str, None, None]:\n    \"\"\"Mock definition of an analysis.\n\n    Example: equity delta and correlation with benchmark.\n\n    Args:\n        benchmark_uuid: Uuid of the benchmark.\n    \"\"\"\n    mock_preparation(\n        MockObject.ANALYSIS,\n        benchmark_name=benchmark_uuid,\n    )\n    analysis_uuid = mock_object(MockObject.ANALYSIS)\n    yield analysis_uuid\n    mock_clean_up(analysis_uuid)\n```\n\nModern approach to Python development leans heavily towards type annotations. Dynamical typing is powerful but can lead to unwieldy code. To properly annotate the `analysis` function we need to import `Generator` from `typing` module. Remember, the `@contextmanager` decorator takes the function and turns it into CM --- a class with `__enter__` and `__exit__` methods. The `Generator` needs three inputs but in our case only the first one is important --- `YieldType`, here `str` ([see](https://docs.python.org/3/library/typing.html#typing.Generator) for more).\n\nWith this done implementing the 3 remaining CMs is easy, just remember our flow chart.\n\n```{python}\n@contextmanager\ndef benchmark() -> Generator[str, None, None]:\n    \"\"\"Mock definition of a benchmark.\n\n    Args:\n        otc_products_uuid: Uuid of the otc products.\n    \"\"\"\n    mock_preparation(\n        MockObject.BENCHMARK,\n    )\n    benchmark_uuid = mock_object(MockObject.BENCHMARK)\n    yield benchmark_uuid\n    mock_clean_up(benchmark_uuid)\n\n\n@contextmanager\ndef otc_products() -> Generator[str, None, None]:\n    \"\"\"Mock definition of an otc products.\n\n    Args:\n        otc_products_uuid: Uuid of the otc products.\n    \"\"\"\n    mock_preparation(MockObject.OTC_PRODUCTS)\n    otcs_uuid = mock_object(MockObject.OTC_PRODUCTS)\n    yield otcs_uuid\n    mock_clean_up(otcs_uuid)\n\n\n@contextmanager\ndef portfolio(\n    *,\n    portfolio_name: str,\n    otc_products_uuid: str,\n) -> Generator[str, None, None]:\n    \"\"\"Mock definition of a portfolio.\n\n    Args:\n        otc_products_uuid: Uuid of the otc products.\n    \"\"\"\n    mock_preparation(\n        MockObject.PORTFOLIO,\n        portfolio_name=portfolio_name,\n        otc_products_uuid=otc_products_uuid,\n    )\n    portfolio_uuid = mock_object(MockObject.PORTFOLIO)\n    yield portfolio_uuid\n    mock_clean_up(portfolio_uuid)\n```\n\n### Analysis results\n\nNo stress or complexity here, to run the analysis we need to specify which analysis to run on which portfolio.\n\n```{python}\nimport pandas as pd\n\ndef analysis_results(\n    *,\n    analysis_uuid: str,\n    portfolio_uuid: str,\n) -> pd.DataFrame:\n    \"\"\"Mock running the analysis on a given portfolio.\n\n    Returns empty dataframe.\n\n    Args:\n        analysis_uuid: Uuid of the analysis.\n        portfolio_uuid: Uuid of the portfolio.\n    \"\"\"\n    print(f\"Running analysis {analysis_uuid} on portfolio {portfolio_uuid}.\")\n    return pd.DataFrame()\n```\n\n##\n\nFinally, we can run some (mock) risk analysis!\n\n### Using contexts directly\n\nFirst, we use the managers directly through `with` clause, remembering the dependencies from our flow chart.\n\n```{python}\nPORTFOLIO = \"portfolio_1\"\n\ndef run_analysis() -> pd.DataFrame:\n    \"\"\"Mock running the analysis using with clauses.\"\"\"\n    with otc_products() as otc_uuid:\n        with benchmark() as benchmark_uuid:\n            with portfolio(\n                portfolio_name=PORTFOLIO,\n                otc_products_uuid=otc_uuid,\n            ) as portfolio_uuid:\n                with analysis(\n                    benchmark_uuid=benchmark_uuid,\n                ) as analysis_uuid:\n                    results = analysis_results(\n                        analysis_uuid=analysis_uuid,\n                        portfolio_uuid=portfolio_uuid,\n                    )\n    return results\n```\n\nThis is terrible! I am already getting lost, needed few tries to get it right. We ended up with **6** levels of indentation, the code is confusing, the flow is obtuse. Let's run it either way, to see if at least works.\n\n```{python}\ndef print_title(title: str) -> None:\n    \"\"\"Print a title padded, surrounded by dashes and empty lines.\"\"\"\n    print(\"\\n\" + title.center(60, \"-\") + \"\\n\")\n\nprint_title(\"Running analysis.\")\nrun_analysis()\n```\n\nGreat, the behaviour is as expected, everything is cleaned after nicely. We achieved the goal but the code is unmaintainable. Looks like a subject of the joke *\"good code makes your job safe for a day, but terrible code in production makes it safe for a lifetime\"*. Being reckless and with no regard to job security as we are, we'll fix it.\n\n*I can clearly recall the most unamanagable and unreadable code I've seen in my career and the culprit was fired in the end. Different reasons, long time later, but still. So the joke is just a joke, don't rely on a bad code as your job insurance.*\n\n## The ExitStack\n\nHere comes in the MVP --- `ExitStack` from `contextlib`, made for streamlining complex context managment situationships. Conceptually it's just a First-In-Last-Out (FILO) stack. You put CMs on top, one by one. When CM is pushed to stack, its `__enter__` method is called and you can intercept the result. ExitStack is a CM itself, it's `__exit__` method is just calling the exits of CMs in reverse order.\n\n```{mermaid}\nflowchart LR\n    A(Enter CM A) ---> B(Enter CM B)\n    B ---> C(Enter CM C)\n    C ---> D[Do stuff]\n    D ---> E(Exit CM C)\n    E ---> F(Exit CM B)\n    F ---> G(Exit CM A)\n    A -.- G\n    B -.- F\n    C -.- E\n\n```\n\nSo the flow is exactly the same as in our first attempt. Let's try it!\n\n```{python}\nfrom contextlib import ExitStack\n\ndef run_analysis_with_exit_stack() -> None:\n    \"\"\"Mock running the analysis using exit stack.\"\"\"\n    with ExitStack() as stack:\n        otc_uuid = stack.enter_context(otc_products())\n        benchmark_uuid = stack.enter_context(benchmark())\n        portfolio_uuid = stack.enter_context(\n            portfolio(\n                portfolio_name=PORTFOLIO,\n                otc_products_uuid=otc_uuid,\n            )\n        )\n        analysis_uuid = stack.enter_context(\n            analysis(\n                benchmark_uuid=benchmark_uuid,\n            )\n        )\n        results = analysis_results(\n            analysis_uuid=analysis_uuid,\n            portfolio_uuid=portfolio_uuid,\n        )\n```\n\nThat's amazing (if the approach works)! In our code we end up with only single `with` clause and the outputs of CMs are defined just like the regular variables. We just need to wrap the CM calls in `stack.enter_context` method that pushes each CM to the stack.\n\n```{python}\nprint_title(\"Running analysis with exit stack.\")\nrun_analysis_with_exit_stack()\n\n```\n\nIt works as well! We also get a package of benefits for free.\n\n### Disabling the clean up\n\nWorking with API is tricky and debugging could be a painful experience. If we notice something iffy with the results we are reciving, it could be due to a bug at any of the stages. In such case disabling the artifact clean up and examining them is a good way to investigate. How do we do that? Comment out the exit code in our resource CMs? Nope, now we know better. With exit stack approach we just need to clean up the stack before exiting its context.\n\n```{python}\ndef run_analysis_with_exit_stack(\n    clean_up: bool = True,\n) -> None:\n    \"\"\"Mock running the analysis using exit stack.\n\n    Args:\n        clean_up: Whether to clean up after the objects.\n    \"\"\"\n\n    with ExitStack() as stack:\n        otc_uuid = stack.enter_context(otc_products())\n        benchmark_uuid = stack.enter_context(benchmark())\n        portfolio_uuid = stack.enter_context(\n            portfolio(\n                portfolio_name=PORTFOLIO,\n                otc_products_uuid=otc_uuid,\n            )\n        )\n        analysis_uuid = stack.enter_context(\n            analysis(\n                benchmark_uuid=benchmark_uuid,\n            )\n        )\n        results = analysis_results(\n            analysis_uuid=analysis_uuid,\n            portfolio_uuid=portfolio_uuid,\n        )\n\n        if not clean_up:\n            _ = stack.pop_all()\n    return results\n```\n\nThe `_ = some_function()` is a Pythonic way of disregarding outputs of `some_function`. Method `pop_all` actually moves the stack contents to a new stack, but we don't care about that. We just want to get rid of them from our current one.\n\n```{python}\nprint_title(\"Running analysis with exit stack and no clean up.\")\nrun_analysis_with_exit_stack(clean_up=False)\n```\n\n### Multiple portfolios\n\nBenefit #2 --- what do we do if we have multiple managers and many portfolios to re-run for? Or --- outside of the example scope --- we want to held multiple files open at the same time? Easy, we just push to the stack in a loop or a list comprehension.\n\n```{python}\nPORTFOLIOS = [\"portfolio_1\", \"portfolio_2\", \"portfolio_3\"]\n\ndef run_analysis_with_exit_stack(clean_up: bool = True):\n    \"\"\"Mock running the analysis for multiple portfolios using exit stack.\n\n    Args:\n        clean_up: Whether to clean up after the objects.\n    \"\"\"\n    with ExitStack() as stack:\n        otc_uuid = stack.enter_context(otc_products())\n        benchmark_uuid = stack.enter_context(benchmark())\n        portfolio_uuids = [\n            stack.enter_context(\n                portfolio(\n                    portfolio_name=portfolio_name,\n                    otc_products_uuid=otc_uuid,\n                )\n            )\n            for portfolio_name in PORTFOLIOS\n        ]\n        analysis_uuid = stack.enter_context(\n            analysis(\n                benchmark_uuid=benchmark_uuid,\n            )\n        )\n        result_parts = [\n            analysis_results(\n                analysis_uuid=analysis_uuid,\n                portfolio_uuid=portfolio_uuid,\n            )\n            for portfolio_uuid in portfolio_uuids\n        ]\n        results = pd.concat(result_parts)\n\n        if not clean_up:\n            _ = stack.pop_all()\n    return results\n\nprint_title(\"Running analysis with exit stack on multiple portfolios.\")\nrun_analysis_with_exit_stack(clean_up=True)\n```\n\n## Conclusion\n\nToday we've learnt a new Python tool and seen an example of how quantitative developer might set up risk reporting job on vendor RMS. Sound like a very niche and unlikely situation for you? Maybe. But the moral here is to go and explore the Python standard library. Without using any additional packages we improved readability and flexibility of our initial attempt. Python really has *'batteries included'*, [see](https://docs.python.org/3/library/index.html) for yourself!\n\n::: callout-note\nDownload the whole code [here](../../scripts/exit_stack.py).\n:::\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":true,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"jupyter"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":true,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true,"format-links":["html"]},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../../styles.css"],"toc":true,"highlight-style":"github","output-file":"index.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.5.57","theme":{"dark":["darkly","../../theme-dark.scss"],"light":"flatly"},"title-block-banner":true,"code-copy":true,"code-block-border-left":true,"title":"Exit stack to the rescue","description":"How to chain resource managers in an elegant way.","author":"bwrob","date":"2024-05-12","date-modified":"2024-08-30","categories":["Pythonic Distractions","Context Managers"],"image":"flowchart.png"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}