{
  "hash": "1a948aaf317c0e997b31ad73b42107ee",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Strategies for Numerical Integration\"\ndescription: \"How to apply strategy design pattern to decouple integration problem from method it's solved with.\"\nauthor: \"bwrob\"\n\ndate: \"2024-04-28\"\n\ncategories: [Pythonic Distractions, Design Patterns]\n---\n\n## Numerical integration\n\nCalculation of many financial methods or metrics relies on a mathematical tool called numerical integration. In simple terms, numerical integration takes a function that represents a continuous process (like the changing value of an investment over time) and approximates the area under its curve. This area can then be used to calculate important quantities, like the total return of the investment or price of a derivative instrument.\n\nSo we are tasked with a problem, and one that has many different ways of solving, or rather approximating the solution. You most likely (taking into account you're still reading this) encountered rectangle rule, or Riemann summation in your Calculus 101 course/self-learning. But there are many other techniques, which we call schemes.\n\nFor quantitative analysts, the choice of the integration method matters. Different integration schemes offer varying levels of accuracy and efficiency. Unfortunately there's no *best technique*. Same algorithm can be a perfect fit for problems with certain characteristics, but unusable for others. And then there is the old as time performance vs. accuracy trade-off.\n\nAs programmers working in finance, we need to be adaptable and leverage solutions that allow us to switch between these methods seamlessly.\n\n## Design patterns\n\nThis is where design patterns come in. Design patterns are reusable solutions to common programming problems. Their widespread adoption in software development is largely attributed to the publication of [Design Patterns: Elements of Reusable Object-Oriented Software](https://www.oreilly.com/library/view/design-patterns-elements/0201633612/) in 1994. Authored by E. Gamma, R. Helm, R. Johnson, and J. Vlissides (often referred to as the \"Gang of Four\" or GoF), this book cataloged 23 essential software design patterns. These patterns provided solutions to common design problems in object-oriented programming, promoting code reusability, maintainability, and flexibility.\n\nSome design patterns can feel clunky or inelegant when implemented in Python. The language itself often has built-in features or idioms that achieve the same result in a more Pythonic way (meaning it follows Python's style and conventions). Sometimes, design patterns can be seen as overcomplicating simple problems. On the other hand, usage of well-known and understood patterns may enhance your engineering skills and improve code readability.\n\nUltimately, the decision of whether or not to use design patterns in Python depends on the specific context of your project and your coding style. There's no right or wrong answer. But first, you need to know the classics to diss the classics. We'll hold on with the dissing for now, cause in the example below chosen design pattern makes for a very clean implementation. You'll see for yourself.\n\n## Strategy pattern\n\nWe know the stage now --- one problem statement, multiple strategies to tackle. Important observation here is that we don't actually care which one is used. When you substitute the integral value to client code --- a formula or further algorithm --- it's irrelevant how it was computed, as long its correct to required level of accuracy. This means that the problem should be decoupled from algorithms to solve it. We should target a implementation where you can state a problem *Calculate the integral of* $\\sin(x)$ *from* $0$ *to* $\\pi$ and then just throw different algorithms at it to obtain a solution. So let's get coding!\n\n::: callout-note\nI will show you this pattern through an example. If you prefer more generic setup see Refactoring Guru's [implementation](https://refactoring.guru/design-patterns/strategy/python/example). The customary 'software engineering' example used to present the SDP is sorting a list of integers using different sorting algorithms.\n:::\n\n## Abstract schema\n\nEach scheme that we'd come up with, even the most complex ones, would have the same main purpose --- 'integrate'. To make the implementation for it, we create a template class that all concrete schemes will inherit from.\n\n::: {#8d723697 .cell execution_count=1}\n``` {.python .cell-code}\nfrom abc import ABC, abstractmethod\nfrom typing import Callable\n\nclass IntegrationScheme(ABC):\n    \"\"\"Abstract base class for integration schemas.\"\"\"\n\n    @abstractmethod\n    def integrate(\n        self,\n        integrand: Callable[[float], float],\n        *,\n        start: float,\n        end: float,\n    ) -> float:\n        \"\"\"Abstract method for integrating a function.\"\"\"\n```\n:::\n\n\nUnpacking this, we already used some nifty Pythonic tricks in those few lines:\n\n-   `ABC` is a way of defining abstract classes. If you try to create an object of a class inheriting from `ABC` you'd get an error. It is used as a base class for concrete subclasses and serves as a template. Think of an example of *animal* and *cat* from the real world. You've never seen an abstract animal being in your life (that would be a truly transcendental experience). But you've hopefully seen many cats.\n-   Decorator `@abstractmethod` signifies that the method is just a mock-up. It needs to be present and overridden in all concrete classes that inherit from `IntegrationScheme`\n-   Type annotations like `start: float` don't affect the script behavior in any way. Those are only for us to not get lost in Python's dynamic typing magic. They can also be leveraged by static type checkers like [mypy](https://mypy.readthedocs.io/en/stable/#) to flag problems with your code before you run it --- just like in compiled languages.\n-   `Callable` annotation signifies a function-like object something you can *call* through `()`, like `some_func(one, second=two)`' --- here `some_func` is a callable. Calls to an object can be implemented by writing the `__call__` method for the class.\n\n## Concrete schema implementations\n\n### Rectangle Rule\n\nIt's the simplest way of estimating the area under a curve you can think of --- cover it with smaller and smaller rectangles with the value of a function at the leftmost point as height constant width.\n\n[![](Rectangle_rule.gif){width=\"100%\"}](https://en.wikipedia.org/wiki/File:Rectangle_rule.gif)\n\nImplementing this idea is trivial when using [numpy](https://numpy.org/), but let's add some syntactic sugar so the class is sweeter to work with.\n\n::: {#d9770415 .cell execution_count=2}\n``` {.python .cell-code}\nimport numpy as np\n\nclass RectangleScheme(IntegrationScheme):\n    \"\"\"Schema for rectangle integration.\"\"\"\n\n    def __init__(\n        self,\n        steps: int,\n    ) -> None:\n        \"\"\"Initializes the rectangle integration config.\"\"\"\n        if steps <= 0:\n            raise ValueError(\"Steps must be greater than 0.\")\n        self._steps = steps\n\n    def __str__(self) -> str:\n        \"\"\"Returns the string representation of the schema.\"\"\"\n        return f\"Rectangle schema with {self._steps} steps\"\n\n    def integrate(\n        self,\n        integrand: Callable[[float], float],\n        *,\n        start: float,\n        end: float,\n    ) -> float:\n        \"\"\"Integrates a function using rectangle integration.\"\"\"\n        x_points = np.linspace(start, end, self._steps)\n        values = integrand(x_points)\n        dx = (end - start) / np.float64(self._steps)\n        return np.sum(values) * dx\n```\n:::\n\n\n-   `RectangleScheme` subclasses `IntegrationScheme` so we need to implement the `integrate` method.\n-   `__init__` method is run each time object of this class is requested. It sets the stage --- in this case all we need is the number of rectangles we are to use. To be cautious, we check if the `steps` number is positive.\n-   `__str__` is called when we try to represent the object as string --- ex. in f-strings or directly calling `str()`. We just taught our class objects to introduce themselves nicely.\n-   `integrate` is as simple as the idea behind it:\n    -   get the equaly spaced x values,\n    -   calculate `integrand` values at the points,\n    -   sum it up,\n    -   multiply the sum by the distance between two consecutive points.\n\n### Simple Monte Carlo\n\nThis guy sounds fancy with its luxurious Monaco vibes, but it's just a peasant in a nice suit. Instead of looking at equaly-spaced points, we shuffle them from uniform distribution on the interval of integration. We calculate the integrand function values at those points and sum them up. Then multiply the sum by the average distance between points and through the magic of probability theory (and not opening actual probability textbook in 10 years) you get a good probabilistic estimator of the integral value. The implementation is analogous to the `RectangleScheme`.\n\n::: {#ebdb9068 .cell execution_count=3}\n``` {.python .cell-code}\nfrom typing import Optional\n\nclass MonteCarloScheme(IntegrationScheme):\n    \"\"\"Schema for Monte Carlo integration.\"\"\"\n\n    def __init__(\n        self,\n        random_points: int,\n        random_seed: Optional[int] = None,\n    ) -> None:\n        \"\"\"Initializes the rectangle integration config.\"\"\"\n        if random_points <= 0:\n            raise ValueError(\"Points must be greater than 0.\")\n        self.__random_points = random_points\n        self.__random_seed = random_seed\n\n    def __str__(self) -> str:\n        \"\"\"Returns the string representation of the schema.\"\"\"\n        points_msg = f\"Monte Carlo schema with {self.__random_points} random points\"\n        seed_msg = f\" and seed {self.__random_seed}\" if self.__random_seed else \"\"\n        return f\"{points_msg}{seed_msg}\"\n\n    def integrate(\n        self,\n        integrand: Callable[[float], float],\n        *,\n        start: float,\n        end: float,\n    ) -> float:\n        \"\"\"Integrates a function using Monte Carlo integration.\"\"\"\n        np.random.seed(seed=self.__random_seed)\n        x_points = np.random.uniform(start, end, self.__random_points)\n        values = integrand(x_points)\n        average_dx = (end - start) / np.float64(self.__random_points)\n        return np.sum(values) * average_dx\n```\n:::\n\n\n-   `Optional[int]` annotation means that the value of `random_seed` can be a `float` or `None`. With a set seed we get a reproducable results --- good for testing but not for actual usage. Hence the default value here is `None`.\n\n::: callout-note\nThe `Optional` stands for *could be `None` as well*, it doesn't affect if the input is mandatory or not. In our case it's not, but thats stated by the `= None` part. In Python 3.11 onwards it's recommended to use `int | None` instead.\n:::\n\n## Integrator\n\nWhat's left is to have a way of defining the problem to solve and define how our schemes (strategies) interact with it.\n\n::: {#134f1c55 .cell execution_count=4}\n``` {.python .cell-code}\n\"\"\"An integrator class that allows to perform integration using different schemas.\"\"\"\nfrom typing import Callable\n\nclass Integrator:\n    \"\"\"An integrator class that allows to perform integration using different\n    schemas as strategies.\"\"\"\n\n    def __init__(\n        self,\n        integrand: Callable[[float], float],\n        interval_start: float,\n        interval_end: float,\n    ) -> None:\n        \"\"\"Initializes the integrator class.\"\"\"\n        if interval_start >= interval_end:\n            raise ValueError(\"Start value must be less than end value.\")\n        self.__integrand = integrand\n        self.__interval_start = interval_start\n        self.__interval_end = interval_end\n\n    def __call__(\n        self,\n        schema: IntegrationScheme,\n    ) -> float:\n        \"\"\"\n        Calculates the definite integral value of a function.\n\n        Args:\n            schema: integration schema\n        \"\"\"\n        print(f\"Using {schema}.\")\n        return schema.integrate(\n            self.__integrand,\n            start=self.__interval_start,\n            end=self.__interval_end,\n        )\n```\n:::\n\n\n-   The `__init__` takes in the obvious parameters --- function to integrate, start and end of the interval. It also checks if it's a proper integral.\n-   We get to implement our own `__call__` method now. It's clear what `Integrator` class does. No need to have a method with a descriptive name like `Integrator.integrate`. To use it you pass through the integration scheme into the integrator --- notice annotation of the abstract `IntegrationScheme`. It prints the info on strategy used (using the `__str__` methods) and calls `integrate` method of the scheme. No care in the world on how the value is actually calculated.\n\n## Let's integrate!\n\nOk, now to the integrating! Let's set up the stage:\n\n::: {#a11b5f26 .cell execution_count=5}\n``` {.python .cell-code}\nstart, end = 0, np.pi / 2.0\n\ndef f(x: float) -> float:\n    return np.sin(x) + np.cos(x)\n```\n:::\n\n\nExcited? Don't be... yet.\n\nWe should get some benchmark value first. As none of us would bother to integrate this by hand, we'll use SciPy. Unexpectedly (SciPy uses C and Fortran underneath), we get the result in a breeze and it is very close to [actual value of 2.0](https://www.wolframalpha.com/input?i=integrate+sin%28x%29+%2B+cos%28x%29+over+0+to+pi%2F2).\n\n::: {#c9308583 .cell execution_count=6}\n``` {.python .cell-code}\nfrom scipy.integrate import quad\n\nscipy_quad, err = quad(f, start, end)\nprint(scipy_quad)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n1.9999999999999998\n```\n:::\n:::\n\n\nNow let's use our `Integrator` class and see.\n\n::: {#57b3692f .cell execution_count=7}\n``` {.python .cell-code}\nintegrator = Integrator(\n    f,\n    interval_start=start,\n    interval_end=end,\n)\n\niterations = [2**i for i in range(0,21,5)]\nrectangle_results = [integrator(RectangleScheme(steps=i)) for i in iterations]\nmc_results = [integrator(MonteCarloScheme(random_points=i)) for i in iterations]\n\nprint(f\"Rectangle schema results:\\n{rectangle_results}.\")\nprint(f\"Monte Carlo schema results:\\n{mc_results}.\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nUsing Rectangle schema with 1 steps.\nUsing Rectangle schema with 32 steps.\nUsing Rectangle schema with 1024 steps.\nUsing Rectangle schema with 32768 steps.\nUsing Rectangle schema with 1048576 steps.\nUsing Monte Carlo schema with 1 random points.\nUsing Monte Carlo schema with 32 random points.\nUsing Monte Carlo schema with 1024 random points.\nUsing Monte Carlo schema with 32768 random points.\nUsing Monte Carlo schema with 1048576 random points.\nRectangle schema results:\n[1.5707963267948966, 1.986172817555692, 1.9995804632216618, 1.9999869013603688, 1.9999995906791057].\nMonte Carlo schema results:\n[2.1745847319663483, 1.9834803268360817, 1.9997296570582257, 1.9978756367376629, 1.9998878735260959].\n```\n:::\n:::\n\n\nThe performance and convergence of those schemes is terrible. Like anything in Python, if you want robust and performing code, you need to implement it with C or use any/all of the enhancement frameworks that Python provides (see Numba). Additionally, the simple methods we implemented are very naive. The standard numerical packages use sophisticated algorithms honed for many decades.\n\nBut I was wrong! You *should* be excited! We just learned new approach for setting up extensible and readable code! Look how cleanly the problem statement is separated form different strategies to solve it.\n\nIf you are now wondering how much we could improve by using more advanced techniques (like [stratified Monte Carlo](http://proceedings.mlr.press/v28/carpentier13.pdf) or [adaptive quadrature](https://www.wikiwand.com/en/Adaptive_quadrature)) you just need to implement new subclass of \\`IntegrationSchema' and you're done. No changes to the existing code are needed, just simple extension. And that's the idea behind strategy pattern.\n\n::: callout-note\nDownload the whole code [here](integration.py).\n:::\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {}
  }
}