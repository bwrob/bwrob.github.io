[
  {
    "objectID": "posts/240512_exit_stack/index.html",
    "href": "posts/240512_exit_stack/index.html",
    "title": "Exit stack to the rescue",
    "section": "",
    "text": "As a quantitative finance professional you’ll often find yourself with risk management systems (RMS). RMS’s are extensive frameworks that let you properly define a book (portfolio) of your financial transactions and run varia of pricing and risk analysis on it. For big financial players, like investment banks, the RMS will be internal proprietary framework that is run in-house. For smaller enterprises or second-line reporting it’s not feasable to tackle creating such vast framework. Hence, where there’s a need, someone will try to make money on it. This leads us to third-party (or vendor) RMS, of which there are plenty (ex. Murex, Acadia).\nWorking with vendor RMS, especially one that covers computations for you, entails juggling multiple resources to obtain your risk metrics. Defining OTC products, benchmarks, portfolios, and running risk analysis can involve numerous API calls, each requiring proper setup and cleanup. This can lead to messy code and potential errors or performance bottlenecks if resources aren’t handled correctly.\nThankfully, Python provides a powerful concept called context managers (CM) that streamline resource managment. True to the language’s ‘batteries included’ philosophy, there’s also a contextlib library that contains variety of tools for easing up your work with CMs. Today we’ll look at a (mock-up) usage of ExitStack class in real-life scenario of running risk analysis on RMS. If you need a refresher on CMs, check out this tutorial by RealPython."
  },
  {
    "objectID": "posts/240512_exit_stack/index.html#working-with-risk-managment-systems",
    "href": "posts/240512_exit_stack/index.html#working-with-risk-managment-systems",
    "title": "Exit stack to the rescue",
    "section": "",
    "text": "As a quantitative finance professional you’ll often find yourself with risk management systems (RMS). RMS’s are extensive frameworks that let you properly define a book (portfolio) of your financial transactions and run varia of pricing and risk analysis on it. For big financial players, like investment banks, the RMS will be internal proprietary framework that is run in-house. For smaller enterprises or second-line reporting it’s not feasable to tackle creating such vast framework. Hence, where there’s a need, someone will try to make money on it. This leads us to third-party (or vendor) RMS, of which there are plenty (ex. Murex, Acadia).\nWorking with vendor RMS, especially one that covers computations for you, entails juggling multiple resources to obtain your risk metrics. Defining OTC products, benchmarks, portfolios, and running risk analysis can involve numerous API calls, each requiring proper setup and cleanup. This can lead to messy code and potential errors or performance bottlenecks if resources aren’t handled correctly.\nThankfully, Python provides a powerful concept called context managers (CM) that streamline resource managment. True to the language’s ‘batteries included’ philosophy, there’s also a contextlib library that contains variety of tools for easing up your work with CMs. Today we’ll look at a (mock-up) usage of ExitStack class in real-life scenario of running risk analysis on RMS. If you need a refresher on CMs, check out this tutorial by RealPython."
  },
  {
    "objectID": "posts/240512_exit_stack/index.html#setting-the-stage",
    "href": "posts/240512_exit_stack/index.html#setting-the-stage",
    "title": "Exit stack to the rescue",
    "section": "Setting the stage",
    "text": "Setting the stage\nTo run an analysis, the RMS first needs to know what our positions are. In case of tradable assets it’s simple — we provide a market identifier and how much of the instrument we are holding. What do we do if we have some bespoke agreement with specific counterparty (an over-the-counter transaction)? We will need to define it from scratch in the RMS using data from the term sheet (assuming this kind of agreement is covered).\nNext, we need to specify the risk metrics we want to calculate — define the analysis scope. Let’s say we hold some equity options and we are intertested in their deltas and beta exposures. The betas are defined with respect to some benchmark — ex. portfolio holding 1 stock in US500 ETF. So we define the benchmark and link it to our analysis.\nFinally — once portfolio and analysis are defined in RMS — we call the API to start the calculation and respond with results. This is the control flow we execute to get to this point:\n\n\n\n\n\nflowchart LR\n  A[OTC Products] --&gt; B[Portfolio]\n  B --&gt; C{Analysis Run}\n  D[Benchmarks] --&gt; E[Analysis Definition]\n  E --&gt; C\n  C --&gt; F(Results)\n\n\n\n\n\n\nIf we know we’re never going to use all of the resources, we should clean up the server artifacts after receving the results. So for each resource we should have a CM.\n\nMock functions\nThe setup described above comes from a real-life situation I worked through. I can’t show you the actual API usage or data (or even the name of RMS itself), so we need to define some mocker functions. Mocks like this are actually not an uncommon thing — such approach is prevalent in testing API client code. In our case it would look like this:\n\nfrom enum import StrEnum\nfrom uuid import uuid4\n\n\nclass MockObject(StrEnum):\n    \"\"\"Types of mock objects.\"\"\"\n\n    ANALYSIS = \"analysis\"\n    BENCHMARK = \"benchmark\"\n    OTC_PRODUCTS = \"otc_products\"\n    PORTFOLIO = \"portfolio\"\n\n\ndef mock_object(object_type: MockObject) -&gt; str:\n    \"\"\"Mock a UUID for a given object type.\n\n    Args:\n        object_type: Type of object.\n    \"\"\"\n    return f\"{object_type}_{uuid4()}\"\n\n\ndef mock_preparation(object_type: MockObject, **kwargs) -&gt; None:\n    \"\"\"Mock preparation of an object.\n\n    Args:\n        object_type: Type of object.\n    \"\"\"\n    print(f\"Preparing {object_type}\" + (f\" using {kwargs}\" if kwargs else \".\"))\n\n\ndef mock_clean_up(object_uuid: str) -&gt; None:\n    \"\"\"Mock clean up of an object.\n\n    Args:\n        object_uuid: Uuid of the object.\n    \"\"\"\n    print(f\"Cleaning up after {object_uuid}.\")\n\nFor each of the four types of resources we mock the preparation, object (ex. API response, some id of definition on server) and the clean up process.\n\n\nContext managers\nEasiest way to define a CM is through contextlib.contextmanager decorator. To use it, you need a function that returns a generator. Code executed on enter should come before yield statement and the one for the exit afterwards. The generator yields the result of the CM (ex. handle to an opened file), the y in with x(*args) as y:.\n\nfrom contextlib import contextmanager\nfrom typing import Generator\n\n@contextmanager\ndef analysis(\n    *,\n    benchmark_uuid: str,\n) -&gt; Generator[str, None, None]:\n    \"\"\"Mock definition of an analysis.\n\n    Example: equity delta and correlation with benchmark.\n\n    Args:\n        benchmark_uuid: Uuid of the benchmark.\n    \"\"\"\n    mock_preparation(\n        MockObject.ANALYSIS,\n        benchmark_name=benchmark_uuid,\n    )\n    analysis_uuid = mock_object(MockObject.ANALYSIS)\n    yield analysis_uuid\n    mock_clean_up(analysis_uuid)\n\nModern approach to Python development leans heavily towards type annotations. Dynamical typing is powerful but can lead to unwieldy code. To properly annotate the analysis function we need to import Generator from typing module. Remember, the @contextmanager decorator takes the function and turns it into CM — a class with __enter__ and __exit__ methods. The Generator needs three inputs but in our case only the first one is important — YieldType, here str (see for more).\nWith this done implementing the 3 remaining CMs is easy, just remember our flow chart.\n\n@contextmanager\ndef benchmark() -&gt; Generator[str, None, None]:\n    \"\"\"Mock definition of a benchmark.\n\n    Args:\n        otc_products_uuid: Uuid of the otc products.\n    \"\"\"\n    mock_preparation(\n        MockObject.BENCHMARK,\n    )\n    benchmark_uuid = mock_object(MockObject.BENCHMARK)\n    yield benchmark_uuid\n    mock_clean_up(benchmark_uuid)\n\n\n@contextmanager\ndef otc_products() -&gt; Generator[str, None, None]:\n    \"\"\"Mock definition of an otc products.\n\n    Args:\n        otc_products_uuid: Uuid of the otc products.\n    \"\"\"\n    mock_preparation(MockObject.OTC_PRODUCTS)\n    otcs_uuid = mock_object(MockObject.OTC_PRODUCTS)\n    yield otcs_uuid\n    mock_clean_up(otcs_uuid)\n\n\n@contextmanager\ndef portfolio(\n    *,\n    portfolio_name: str,\n    otc_products_uuid: str,\n) -&gt; Generator[str, None, None]:\n    \"\"\"Mock definition of a portfolio.\n\n    Args:\n        otc_products_uuid: Uuid of the otc products.\n    \"\"\"\n    mock_preparation(\n        MockObject.PORTFOLIO,\n        portfolio_name=portfolio_name,\n        otc_products_uuid=otc_products_uuid,\n    )\n    portfolio_uuid = mock_object(MockObject.PORTFOLIO)\n    yield portfolio_uuid\n    mock_clean_up(portfolio_uuid)\n\n\n\nAnalysis results\nNo stress or complexity here, to run the analysis we need to specify which analysis to run on which portfolio.\n\nimport pandas as pd\n\ndef analysis_results(\n    *,\n    analysis_uuid: str,\n    portfolio_uuid: str,\n) -&gt; pd.DataFrame:\n    \"\"\"Mock running the analysis on a given portfolio.\n\n    Returns empty dataframe.\n\n    Args:\n        analysis_uuid: Uuid of the analysis.\n        portfolio_uuid: Uuid of the portfolio.\n    \"\"\"\n    print(f\"Running analysis {analysis_uuid} on portfolio {portfolio_uuid}.\")\n    return pd.DataFrame()"
  },
  {
    "objectID": "posts/240512_exit_stack/index.html#section",
    "href": "posts/240512_exit_stack/index.html#section",
    "title": "Exit stack to the rescue",
    "section": "",
    "text": "Finally, we can run some (mock) risk analysis!\n\nUsing contexts directly\nFirst, we use the managers directly through with clause, remembering the dependencies from our flow chart.\n\nPORTFOLIO = \"portfolio_1\"\n\ndef run_analysis() -&gt; pd.DataFrame:\n    \"\"\"Mock running the analysis using with clauses.\"\"\"\n    with otc_products() as otc_uuid:\n        with benchmark() as benchmark_uuid:\n            with portfolio(\n                portfolio_name=PORTFOLIO,\n                otc_products_uuid=otc_uuid,\n            ) as portfolio_uuid:\n                with analysis(\n                    benchmark_uuid=benchmark_uuid,\n                ) as analysis_uuid:\n                    results = analysis_results(\n                        analysis_uuid=analysis_uuid,\n                        portfolio_uuid=portfolio_uuid,\n                    )\n    return results\n\nThis is terrible! I am already getting lost, needed few tries to get it right. We ended up with 6 levels of indentation, the code is confusing, the flow is obtuse. Let’s run it either way, to see if at least works.\n\ndef print_title(title: str) -&gt; None:\n    \"\"\"Print a title padded, surrounded by dashes and empty lines.\"\"\"\n    print(\"\\n\" + title.center(60, \"-\") + \"\\n\")\n\nprint_title(\"Running analysis.\")\nrun_analysis()\n\n\n---------------------Running analysis.----------------------\n\nPreparing otc_products.\nPreparing benchmark.\nPreparing portfolio using {'portfolio_name': 'portfolio_1', 'otc_products_uuid': 'otc_products_efee9e27-df10-4b7a-b216-30eac8f23552'}\nPreparing analysis using {'benchmark_name': 'benchmark_97535feb-98ba-4743-89df-e557bb2ec4b2'}\nRunning analysis analysis_eb8d3739-aa80-40b8-8625-8b007ad8cf15 on portfolio portfolio_6a74190c-e653-4026-afa1-bcacab59be81.\nCleaning up after analysis_eb8d3739-aa80-40b8-8625-8b007ad8cf15.\nCleaning up after portfolio_6a74190c-e653-4026-afa1-bcacab59be81.\nCleaning up after benchmark_97535feb-98ba-4743-89df-e557bb2ec4b2.\nCleaning up after otc_products_efee9e27-df10-4b7a-b216-30eac8f23552.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGreat, the behaviour is as expected, everything is cleaned after nicely. We achieved the goal but the code is unmaintainable. Looks like a subject of the joke “good code makes your job safe for a day, but terrible code in production makes it safe for a lifetime”. Being reckless and with no regard to job security as we are, we’ll fix it.\nI can clearly recall the most unamanagable and unreadable code I’ve seen in my career and the culprit was fired in the end. Different reasons, long time later, but still. So the joke is just a joke, don’t rely on a bad code as your job insurance."
  },
  {
    "objectID": "posts/240512_exit_stack/index.html#the-exitstack",
    "href": "posts/240512_exit_stack/index.html#the-exitstack",
    "title": "Exit stack to the rescue",
    "section": "The ExitStack",
    "text": "The ExitStack\nHere comes in the MVP — ExitStack from contextlib, made for streamlining complex context managment situationships. Conceptually it’s just a First-In-Last-Out (FILO) stack. You put CMs on top, one by one. When CM is pushed to stack, its __enter__ method is called and you can intercept the result. ExitStack is a CM itself, it’s __exit__ method is just calling the exits of CMs in reverse order.\n\n\n\n\n\nflowchart LR\n    A(Enter CM A) ---&gt; B(Enter CM B)\n    B ---&gt; C(Enter CM C)\n    C ---&gt; D[Do stuff]\n    D ---&gt; E(Exit CM C)\n    E ---&gt; F(Exit CM B)\n    F ---&gt; G(Exit CM A)\n    A -.- G\n    B -.- F\n    C -.- E\n\n\n\n\n\n\n\nSo the flow is exactly the same as in our first attempt. Let’s try it!\n\nfrom contextlib import ExitStack\n\ndef run_analysis_with_exit_stack() -&gt; None:\n    \"\"\"Mock running the analysis using exit stack.\"\"\"\n    with ExitStack() as stack:\n        otc_uuid = stack.enter_context(otc_products())\n        benchmark_uuid = stack.enter_context(benchmark())\n        portfolio_uuid = stack.enter_context(\n            portfolio(\n                portfolio_name=PORTFOLIO,\n                otc_products_uuid=otc_uuid,\n            )\n        )\n        analysis_uuid = stack.enter_context(\n            analysis(\n                benchmark_uuid=benchmark_uuid,\n            )\n        )\n        results = analysis_results(\n            analysis_uuid=analysis_uuid,\n            portfolio_uuid=portfolio_uuid,\n        )\n\nThat’s amazing (if the approach works)! In our code we end up with only single with clause and the outputs of CMs are defined just like the regular variables. We just need to wrap the CM calls in stack.enter_context method that pushes each CM to the stack.\n\nprint_title(\"Running analysis with exit stack.\")\nrun_analysis_with_exit_stack()\n\n\n-------------Running analysis with exit stack.--------------\n\nPreparing otc_products.\nPreparing benchmark.\nPreparing portfolio using {'portfolio_name': 'portfolio_1', 'otc_products_uuid': 'otc_products_a60a51c2-f781-4fcb-8519-45e7180d27b9'}\nPreparing analysis using {'benchmark_name': 'benchmark_a48e3d24-8c6d-4a23-9d17-84336834cde1'}\nRunning analysis analysis_67744945-e773-47d0-b53a-09067fa2ace7 on portfolio portfolio_26e809af-3f36-485a-954f-7873629ea000.\nCleaning up after analysis_67744945-e773-47d0-b53a-09067fa2ace7.\nCleaning up after portfolio_26e809af-3f36-485a-954f-7873629ea000.\nCleaning up after benchmark_a48e3d24-8c6d-4a23-9d17-84336834cde1.\nCleaning up after otc_products_a60a51c2-f781-4fcb-8519-45e7180d27b9.\n\n\nIt works as well! We also get a package of benefits for free.\n\nDisabling the clean up\nWorking with API is tricky and debugging could be a painful experience. If we notice something iffy with the results we are reciving, it could be due to a bug at any of the stages. In such case disabling the artifact clean up and examining them is a good way to investigate. How do we do that? Comment out the exit code in our resource CMs? Nope, now we know better. With exit stack approach we just need to clean up the stack before exiting its context.\n\ndef run_analysis_with_exit_stack(\n    clean_up: bool = True,\n) -&gt; None:\n    \"\"\"Mock running the analysis using exit stack.\n\n    Args:\n        clean_up: Whether to clean up after the objects.\n    \"\"\"\n\n    with ExitStack() as stack:\n        otc_uuid = stack.enter_context(otc_products())\n        benchmark_uuid = stack.enter_context(benchmark())\n        portfolio_uuid = stack.enter_context(\n            portfolio(\n                portfolio_name=PORTFOLIO,\n                otc_products_uuid=otc_uuid,\n            )\n        )\n        analysis_uuid = stack.enter_context(\n            analysis(\n                benchmark_uuid=benchmark_uuid,\n            )\n        )\n        results = analysis_results(\n            analysis_uuid=analysis_uuid,\n            portfolio_uuid=portfolio_uuid,\n        )\n\n        if not clean_up:\n            _ = stack.pop_all()\n    return results\n\nThe _ = some_function() is a Pythonic way of disregarding outputs of some_function. Method pop_all actually moves the stack contents to a new stack, but we don’t care about that. We just want to get rid of them from our current one.\n\nprint_title(\"Running analysis with exit stack and no clean up.\")\nrun_analysis_with_exit_stack(clean_up=False)\n\n\n-----Running analysis with exit stack and no clean up.------\n\nPreparing otc_products.\nPreparing benchmark.\nPreparing portfolio using {'portfolio_name': 'portfolio_1', 'otc_products_uuid': 'otc_products_c75232c1-3926-40d5-a78d-3955cb30c636'}\nPreparing analysis using {'benchmark_name': 'benchmark_92a42f15-910d-416d-b5b5-635613b7e52d'}\nRunning analysis analysis_caa32677-722e-4899-9ea1-77896be0e45a on portfolio portfolio_ee4f418d-6e3c-46a8-922a-a024eb403d52.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMultiple portfolios\nBenefit #2 — what do we do if we have multiple managers and many portfolios to re-run for? Or — outside of the example scope — we want to held multiple files open at the same time? Easy, we just push to the stack in a loop or a list comprehension.\n\nPORTFOLIOS = [\"portfolio_1\", \"portfolio_2\", \"portfolio_3\"]\n\ndef run_analysis_with_exit_stack(clean_up: bool = True):\n    \"\"\"Mock running the analysis for multiple portfolios using exit stack.\n\n    Args:\n        clean_up: Whether to clean up after the objects.\n    \"\"\"\n    with ExitStack() as stack:\n        otc_uuid = stack.enter_context(otc_products())\n        benchmark_uuid = stack.enter_context(benchmark())\n        portfolio_uuids = [\n            stack.enter_context(\n                portfolio(\n                    portfolio_name=portfolio_name,\n                    otc_products_uuid=otc_uuid,\n                )\n            )\n            for portfolio_name in PORTFOLIOS\n        ]\n        analysis_uuid = stack.enter_context(\n            analysis(\n                benchmark_uuid=benchmark_uuid,\n            )\n        )\n        result_parts = [\n            analysis_results(\n                analysis_uuid=analysis_uuid,\n                portfolio_uuid=portfolio_uuid,\n            )\n            for portfolio_uuid in portfolio_uuids\n        ]\n        results = pd.concat(result_parts)\n\n        if not clean_up:\n            _ = stack.pop_all()\n    return results\n\nprint_title(\"Running analysis with exit stack on multiple portfolios.\")\nrun_analysis_with_exit_stack(clean_up=True)\n\n\n--Running analysis with exit stack on multiple portfolios.--\n\nPreparing otc_products.\nPreparing benchmark.\nPreparing portfolio using {'portfolio_name': 'portfolio_1', 'otc_products_uuid': 'otc_products_7af52ed6-6dec-4df1-a6f0-793bb238df4f'}\nPreparing portfolio using {'portfolio_name': 'portfolio_2', 'otc_products_uuid': 'otc_products_7af52ed6-6dec-4df1-a6f0-793bb238df4f'}\nPreparing portfolio using {'portfolio_name': 'portfolio_3', 'otc_products_uuid': 'otc_products_7af52ed6-6dec-4df1-a6f0-793bb238df4f'}\nPreparing analysis using {'benchmark_name': 'benchmark_c0c5e514-a2ba-46c9-874e-dcf2f26185d5'}\nRunning analysis analysis_5f57869b-acc5-4dad-9149-a81ad387c6e1 on portfolio portfolio_f75c0169-0836-481d-9d7a-0d81b2e2e40f.\nRunning analysis analysis_5f57869b-acc5-4dad-9149-a81ad387c6e1 on portfolio portfolio_bfc180f6-66bf-471d-9f3e-5724bc29869d.\nRunning analysis analysis_5f57869b-acc5-4dad-9149-a81ad387c6e1 on portfolio portfolio_7a0b68ba-e847-4c26-8861-a6ede738d4b2.\nCleaning up after analysis_5f57869b-acc5-4dad-9149-a81ad387c6e1.\nCleaning up after portfolio_7a0b68ba-e847-4c26-8861-a6ede738d4b2.\nCleaning up after portfolio_bfc180f6-66bf-471d-9f3e-5724bc29869d.\nCleaning up after portfolio_f75c0169-0836-481d-9d7a-0d81b2e2e40f.\nCleaning up after benchmark_c0c5e514-a2ba-46c9-874e-dcf2f26185d5.\nCleaning up after otc_products_7af52ed6-6dec-4df1-a6f0-793bb238df4f."
  },
  {
    "objectID": "posts/240512_exit_stack/index.html#conclusion",
    "href": "posts/240512_exit_stack/index.html#conclusion",
    "title": "Exit stack to the rescue",
    "section": "Conclusion",
    "text": "Conclusion\nToday we’ve learnt a new Python tool and seen an example of how quantitative developer might set up risk reporting job on vendor RMS. Sound like a very niche and unlikely situation for you? Maybe. But the moral here is to go and explore the Python standard library. Without using any additional packages we improved readability and flexibility of our initial attempt. Python really has ‘batteries included’, see for yourself!"
  },
  {
    "objectID": "posts/240426_strategy_integration/index.html",
    "href": "posts/240426_strategy_integration/index.html",
    "title": "Strategies for Numerical Integration",
    "section": "",
    "text": "Calculation of many financial methods or metrics relies on a mathematical tool called numerical integration. In simple terms, numerical integration takes a function that represents a continuous process (like the changing value of an investment over time) and approximates the area under its curve. This area can then be used to calculate important quantities, like the total return of the investment or price of a derivative instrument.\nSo we are tasked with a problem, and one that has many different ways of solving, or rather approximating the solution. You most likely (taking into account you’re still reading this) encountered rectangle rule, or Riemann summation in your Calculus 101 course/self-learning. But there are many other techniques, which we call schemes.\nFor quantitative analysts, the choice of the integration method matters. Different integration schemes offer varying levels of accuracy and efficiency. Unfortunately there’s no best technique. Same algorithm can be a perfect fit for problems with certain characteristics, but unusable for others. And then there is the old as time performance vs. accuracy trade-off.\nAs programmers working in finance, we need to be adaptable and leverage solutions that allow us to switch between these methods seamlessly."
  },
  {
    "objectID": "posts/240426_strategy_integration/index.html#numerical-integration",
    "href": "posts/240426_strategy_integration/index.html#numerical-integration",
    "title": "Strategies for Numerical Integration",
    "section": "",
    "text": "Calculation of many financial methods or metrics relies on a mathematical tool called numerical integration. In simple terms, numerical integration takes a function that represents a continuous process (like the changing value of an investment over time) and approximates the area under its curve. This area can then be used to calculate important quantities, like the total return of the investment or price of a derivative instrument.\nSo we are tasked with a problem, and one that has many different ways of solving, or rather approximating the solution. You most likely (taking into account you’re still reading this) encountered rectangle rule, or Riemann summation in your Calculus 101 course/self-learning. But there are many other techniques, which we call schemes.\nFor quantitative analysts, the choice of the integration method matters. Different integration schemes offer varying levels of accuracy and efficiency. Unfortunately there’s no best technique. Same algorithm can be a perfect fit for problems with certain characteristics, but unusable for others. And then there is the old as time performance vs. accuracy trade-off.\nAs programmers working in finance, we need to be adaptable and leverage solutions that allow us to switch between these methods seamlessly."
  },
  {
    "objectID": "posts/240426_strategy_integration/index.html#design-patterns",
    "href": "posts/240426_strategy_integration/index.html#design-patterns",
    "title": "Strategies for Numerical Integration",
    "section": "Design patterns",
    "text": "Design patterns\nThis is where design patterns come in. Design patterns are reusable solutions to common programming problems. Their widespread adoption in software development is largely attributed to the publication of Design Patterns: Elements of Reusable Object-Oriented Software in 1994. Authored by E. Gamma, R. Helm, R. Johnson, and J. Vlissides (often referred to as the “Gang of Four” or GoF), this book cataloged 23 essential software design patterns. These patterns provided solutions to common design problems in object-oriented programming, promoting code reusability, maintainability, and flexibility.\nSome design patterns can feel clunky or inelegant when implemented in Python. The language itself often has built-in features or idioms that achieve the same result in a more Pythonic way (meaning it follows Python’s style and conventions). Sometimes, design patterns can be seen as overcomplicating simple problems. On the other hand, usage of well-known and understood patterns may enhance your engineering skills and improve code readability.\nUltimately, the decision of whether or not to use design patterns in Python depends on the specific context of your project and your coding style. There’s no right or wrong answer. But first, you need to know the classics to diss the classics. We’ll hold on with the dissing for now, cause in the example below chosen design pattern makes for a very clean implementation. You’ll see for yourself."
  },
  {
    "objectID": "posts/240426_strategy_integration/index.html#strategy-pattern",
    "href": "posts/240426_strategy_integration/index.html#strategy-pattern",
    "title": "Strategies for Numerical Integration",
    "section": "Strategy pattern",
    "text": "Strategy pattern\nWe know the stage now — one problem statement, multiple strategies to tackle. Important observation here is that we don’t actually care which one is used. When you substitute the integral value to client code — a formula or further algorithm — it’s irrelevant how it was computed, as long its correct to required level of accuracy. This means that the problem should be decoupled from algorithms to solve it. We should target a implementation where you can state a problem Calculate the integral of \\(\\sin(x)\\) from \\(0\\) to \\(\\pi\\) and then just throw different algorithms at it to obtain a solution. So let’s get coding!\n\n\n\n\n\n\nNote\n\n\n\nI will show you this pattern through an example. If you prefer more generic setup see Refactoring Guru’s implementation. The customary ‘software engineering’ example used to present the SDP is sorting a list of integers using different sorting algorithms."
  },
  {
    "objectID": "posts/240426_strategy_integration/index.html#abstract-schema",
    "href": "posts/240426_strategy_integration/index.html#abstract-schema",
    "title": "Strategies for Numerical Integration",
    "section": "Abstract schema",
    "text": "Abstract schema\nEach scheme that we’d come up with, even the most complex ones, would have the same main purpose — ‘integrate’. To make the implementation for it, we create a template class that all concrete schemes will inherit from.\n\nfrom abc import ABC, abstractmethod\nfrom typing import Callable\n\nclass IntegrationScheme(ABC):\n    \"\"\"Abstract base class for integration schemas.\"\"\"\n\n    @abstractmethod\n    def integrate(\n        self,\n        integrand: Callable[[float], float],\n        *,\n        start: float,\n        end: float,\n    ) -&gt; float:\n        \"\"\"Abstract method for integrating a function.\"\"\"\n\nUnpacking this, we already used some nifty Pythonic tricks in those few lines:\n\nABC is a way of defining abstract classes. If you try to create an object of a class inheriting from ABC you’d get an error. It is used as a base class for concrete subclasses and serves as a template. Think of an example of animal and cat from the real world. You’ve never seen an abstract animal being in your life (that would be a truly transcendental experience). But you’ve hopefully seen many cats.\nDecorator @abstractmethod signifies that the method is just a mock-up. It needs to be present and overridden in all concrete classes that inherit from IntegrationScheme\nType annotations like start: float don’t affect the script behavior in any way. Those are only for us to not get lost in Python’s dynamic typing magic. They can also be leveraged by static type checkers like mypy to flag problems with your code before you run it — just like in compiled languages.\nCallable annotation signifies a function-like object something you can call through (), like some_func(one, second=two)’ — here some_func is a callable. Calls to an object can be implemented by writing the __call__ method for the class."
  },
  {
    "objectID": "posts/240426_strategy_integration/index.html#concrete-schema-implementations",
    "href": "posts/240426_strategy_integration/index.html#concrete-schema-implementations",
    "title": "Strategies for Numerical Integration",
    "section": "Concrete schema implementations",
    "text": "Concrete schema implementations\n\nRectangle Rule\nIt’s the simplest way of estimating the area under a curve you can think of — cover it with smaller and smaller rectangles with the value of a function at the leftmost point as height constant width.\n\nImplementing this idea is trivial when using numpy, but let’s add some syntactic sugar so the class is sweeter to work with.\n\nimport numpy as np\n\nclass RectangleScheme(IntegrationScheme):\n    \"\"\"Schema for rectangle integration.\"\"\"\n\n    def __init__(\n        self,\n        steps: int,\n    ) -&gt; None:\n        \"\"\"Initializes the rectangle integration config.\"\"\"\n        if steps &lt;= 0:\n            raise ValueError(\"Steps must be greater than 0.\")\n        self._steps = steps\n\n    def __str__(self) -&gt; str:\n        \"\"\"Returns the string representation of the schema.\"\"\"\n        return f\"Rectangle schema with {self._steps} steps\"\n\n    def integrate(\n        self,\n        integrand: Callable[[float], float],\n        *,\n        start: float,\n        end: float,\n    ) -&gt; float:\n        \"\"\"Integrates a function using rectangle integration.\"\"\"\n        x_points = np.linspace(start, end, self._steps)\n        values = integrand(x_points)\n        dx = (end - start) / np.float64(self._steps)\n        return np.sum(values) * dx\n\n\nRectangleScheme subclasses IntegrationScheme so we need to implement the integrate method.\n__init__ method is run each time object of this class is requested. It sets the stage — in this case all we need is the number of rectangles we are to use. To be cautious, we check if the steps number is positive.\n__str__ is called when we try to represent the object as string — ex. in f-strings or directly calling str(). We just taught our class objects to introduce themselves nicely.\nintegrate is as simple as the idea behind it:\n\nget the equaly spaced x values,\ncalculate integrand values at the points,\nsum it up,\nmultiply the sum by the distance between two consecutive points.\n\n\n\n\nSimple Monte Carlo\nThis guy sounds fancy with its luxurious Monaco vibes, but it’s just a peasant in a nice suit. Instead of looking at equaly-spaced points, we shuffle them from uniform distribution on the interval of integration. We calculate the integrand function values at those points and sum them up. Then multiply the sum by the average distance between points and through the magic of probability theory (and not opening actual probability textbook in 10 years) you get a good probabilistic estimator of the integral value. The implementation is analogous to the RectangleScheme.\n\nfrom typing import Optional\n\nclass MonteCarloScheme(IntegrationScheme):\n    \"\"\"Schema for Monte Carlo integration.\"\"\"\n\n    def __init__(\n        self,\n        random_points: int,\n        random_seed: Optional[int] = None,\n    ) -&gt; None:\n        \"\"\"Initializes the rectangle integration config.\"\"\"\n        if random_points &lt;= 0:\n            raise ValueError(\"Points must be greater than 0.\")\n        self.__random_points = random_points\n        self.__random_seed = random_seed\n\n    def __str__(self) -&gt; str:\n        \"\"\"Returns the string representation of the schema.\"\"\"\n        points_msg = f\"Monte Carlo schema with {self.__random_points} random points\"\n        seed_msg = f\" and seed {self.__random_seed}\" if self.__random_seed else \"\"\n        return f\"{points_msg}{seed_msg}\"\n\n    def integrate(\n        self,\n        integrand: Callable[[float], float],\n        *,\n        start: float,\n        end: float,\n    ) -&gt; float:\n        \"\"\"Integrates a function using Monte Carlo integration.\"\"\"\n        np.random.seed(seed=self.__random_seed)\n        x_points = np.random.uniform(start, end, self.__random_points)\n        values = integrand(x_points)\n        average_dx = (end - start) / np.float64(self.__random_points)\n        return np.sum(values) * average_dx\n\n\nOptional[int] annotation means that the value of random_seed can be a float or None. With a set seed we get a reproducable results — good for testing but not for actual usage. Hence the default value here is None.\n\n\n\n\n\n\n\nNote\n\n\n\nThe Optional stands for could be None as well, it doesn’t affect if the input is mandatory or not. In our case it’s not, but thats stated by the = None part. In Python 3.11 onwards it’s recommended to use int | None instead."
  },
  {
    "objectID": "posts/240426_strategy_integration/index.html#integrator",
    "href": "posts/240426_strategy_integration/index.html#integrator",
    "title": "Strategies for Numerical Integration",
    "section": "Integrator",
    "text": "Integrator\nWhat’s left is to have a way of defining the problem to solve and define how our schemes (strategies) interact with it.\n\n\"\"\"An integrator class that allows to perform integration using different schemas.\"\"\"\nfrom typing import Callable\n\nclass Integrator:\n    \"\"\"An integrator class that allows to perform integration using different\n    schemas as strategies.\"\"\"\n\n    def __init__(\n        self,\n        integrand: Callable[[float], float],\n        interval_start: float,\n        interval_end: float,\n    ) -&gt; None:\n        \"\"\"Initializes the integrator class.\"\"\"\n        if interval_start &gt;= interval_end:\n            raise ValueError(\"Start value must be less than end value.\")\n        self.__integrand = integrand\n        self.__interval_start = interval_start\n        self.__interval_end = interval_end\n\n    def __call__(\n        self,\n        schema: IntegrationScheme,\n    ) -&gt; float:\n        \"\"\"\n        Calculates the definite integral value of a function.\n\n        Args:\n            schema: integration schema\n        \"\"\"\n        print(f\"Using {schema}.\")\n        return schema.integrate(\n            self.__integrand,\n            start=self.__interval_start,\n            end=self.__interval_end,\n        )\n\n\nThe __init__ takes in the obvious parameters — function to integrate, start and end of the interval. It also checks if it’s a proper integral.\nWe get to implement our own __call__ method now. It’s clear what Integrator class does. No need to have a method with a descriptive name like Integrator.integrate. To use it you pass through the integration scheme into the integrator — notice annotation of the abstract IntegrationScheme. It prints the info on strategy used (using the __str__ methods) and calls integrate method of the scheme. No care in the world on how the value is actually calculated."
  },
  {
    "objectID": "posts/240426_strategy_integration/index.html#lets-integrate",
    "href": "posts/240426_strategy_integration/index.html#lets-integrate",
    "title": "Strategies for Numerical Integration",
    "section": "Let’s integrate!",
    "text": "Let’s integrate!\nOk, now to the integrating! Let’s set up the stage:\n\nstart, end = 0, np.pi / 2.0\n\ndef f(x: float) -&gt; float:\n    return np.sin(x) + np.cos(x)\n\nExcited? Don’t be… yet.\nWe should get some benchmark value first. As none of us would bother to integrate this by hand, we’ll use SciPy. Unexpectedly (SciPy uses C and Fortran underneath), we get the result in a breeze and it is very close to actual value of 2.0.\n\nfrom scipy.integrate import quad\n\nscipy_quad, err = quad(f, start, end)\nprint(scipy_quad)\n\n1.9999999999999998\n\n\nNow let’s use our Integrator class and see.\n\nintegrator = Integrator(\n    f,\n    interval_start=start,\n    interval_end=end,\n)\n\niterations = [2**i for i in range(0,21,5)]\nrectangle_results = [integrator(RectangleScheme(steps=i)) for i in iterations]\nmc_results = [integrator(MonteCarloScheme(random_points=i)) for i in iterations]\n\nprint(f\"Rectangle schema results:\\n{rectangle_results}.\")\nprint(f\"Monte Carlo schema results:\\n{mc_results}.\")\n\nUsing Rectangle schema with 1 steps.\nUsing Rectangle schema with 32 steps.\nUsing Rectangle schema with 1024 steps.\nUsing Rectangle schema with 32768 steps.\nUsing Rectangle schema with 1048576 steps.\nUsing Monte Carlo schema with 1 random points.\nUsing Monte Carlo schema with 32 random points.\nUsing Monte Carlo schema with 1024 random points.\nUsing Monte Carlo schema with 32768 random points.\nUsing Monte Carlo schema with 1048576 random points.\nRectangle schema results:\n[1.5707963267948966, 1.986172817555692, 1.9995804632216618, 1.9999869013603688, 1.9999995906791057].\nMonte Carlo schema results:\n[2.213767303125614, 1.9696661792974728, 1.986878631098522, 2.001129346968637, 1.9996841123631968].\n\n\nThe performance and convergence of those schemes is terrible. Like anything in Python, if you want robust and performing code, you need to implement it with C or use any/all of the enhancement frameworks that Python provides (see Numba). Additionally, the simple methods we implemented are very naive. The standard numerical packages use sophisticated algorithms honed for many decades.\nBut I was wrong! You should be excited! We just learned new approach for setting up extensible and readable code! Look how cleanly the problem statement is separated form different strategies to solve it.\nIf you are now wondering how much we could improve by using more advanced techniques (like stratified Monte Carlo or adaptive quadrature) you just need to implement new subclass of `IntegrationSchema’ and you’re done. No changes to the existing code are needed, just simple extension. And that’s the idea behind strategy pattern.\n\n\n\n\n\n\nNote\n\n\n\nDownload the whole code here."
  },
  {
    "objectID": "pages/hobbies.html",
    "href": "pages/hobbies.html",
    "title": "Fueling the Mind & Body: My Off-Duty Explorations.",
    "section": "",
    "text": "Supprisingly, I still have some hobbies outside technology and finance. This list is meant to be aspirational – i.e. sort of Instagram take on my interests to motivate me to invest more time into things I like. Too often I find myself in a work-sleep-work cycle that leaves little time for enjoyment.\n\n\nI have a PS5, a NS and a gaming PC. I play only single-player games, enjoy rouge-likes and open-worlds the most. My favorite games are God of War (2018), Hades and Trackmania. If your life’s companion is also a gamer (or just plays a little bit) i highly recommend It Takes Two.\n\n\n\n\nGot two cameras, old big hog Canon 450D and compact and sleek Sony A6000. I can make a decent portrait or Instagram ‘location photo’ but mosty interested in nature and urban settings. Would like to learn more on light and exposure usage, for now I am looking for contrasts and interesting compositions in my photos.\n\n\n\n\nClever ideas that fill and fuel natural sciences are often intimidating. Sure, there are occasional outliers – genius individuals that make history with revolutionary inventions. But most of the progress is achieved by a tectonic creep of incremental small wins and observations. All of those geniuses stood on the shoulders of giants that came before. The history of how those ideas and meanders of knowledge happened can be thrilling and educating.\n\n\n\n\nMaster chef of making tasty meal from leftovers. Specializing in Asian fusion cuisine. Fried rice with pulled tofu? Sushi with beetroot? Korean beef with sauerkraut? Yes, those are all delicious!\n\n\n\n\nI am a proud owner of 90’s vintage road bike. It was recently refurbished and looks smashing! It even has chipset print and binary code on the handles (photo pre-renovation)!\n\n\n\n\nYes, just strolling, but with a philosophy. No headphones, no distractions, no direction. Just observing what changed in the neighborhood I’ve lived in for the last 15 years, and what is happening inside. Think awareness meditation but while walking."
  },
  {
    "objectID": "pages/hobbies.html#road-cycling",
    "href": "pages/hobbies.html#road-cycling",
    "title": "Fueling the Mind & Body: My Off-Duty Explorations.",
    "section": "",
    "text": "I am a proud owner of 90’s vintage road bike. It was recently refurbished and looks smashing! It even has chipset print and binary code on the handles (photo pre-renovation)!"
  },
  {
    "objectID": "pages/hobbies.html#strolling.",
    "href": "pages/hobbies.html#strolling.",
    "title": "Fueling the Mind & Body: My Off-Duty Explorations.",
    "section": "",
    "text": "Yes, just strolling, but with a philosophy. No headphones, no distractions, no direction. Just observing what changed in the neighborhood I’ve lived in for the last 15 years, and what is happening inside. Think awareness meditation but while walking."
  },
  {
    "objectID": "ideas.html",
    "href": "ideas.html",
    "title": "Future post ideas",
    "section": "",
    "text": "see\n\n\n\n\n\nflowchart LR\n  A[Hard edge] --&gt; B(Round edge)\n  B --&gt; C{Decision}\n  C --&gt; D[Result one]\n  C --&gt; E[Result two]\n\n\n\n\n\n\n\n\n\n\n\nsequenceDiagram\n  participant Alice\n  participant Bob\n  Alice-&gt;&gt;John: Hello John, how are you?\n  loop Healthcheck\n    John-&gt;&gt;John: Fight against hypochondria\n  end\n  Note right of John: Rational thoughts &lt;br/&gt;prevail!\n  John--&gt;&gt;Alice: Great!\n  John-&gt;&gt;Bob: How about you?\n  Bob--&gt;&gt;John: Jolly good!\n\n\n\n\n\n\n\n\n\npython Windows startup script\nparallelize pandas apply\nimplied volatility function\nfast IV calculation on milions of options\nIntro to Python data model\n\n\n\n\n\nAncient way of satisfying your trader: C++ in Excel via COM\nNavier-Stokes with shaders\n\n\n\n\n\nwhat is anomalous diffusion?\nhow to start learning maths?\n\n\n\n\n\nTwists and turns of modern career\n\n\n\n\n\nFluent Python\nOut of Crisis\n\n\n\n\n\nhttps://www.youtube.com/watch?v=uimdXPZc40I"
  },
  {
    "objectID": "ideas.html#pythonic-distractions",
    "href": "ideas.html#pythonic-distractions",
    "title": "Future post ideas",
    "section": "",
    "text": "python Windows startup script\nparallelize pandas apply\nimplied volatility function\nfast IV calculation on milions of options\nIntro to Python data model"
  },
  {
    "objectID": "ideas.html#lower-level",
    "href": "ideas.html#lower-level",
    "title": "Future post ideas",
    "section": "",
    "text": "Ancient way of satisfying your trader: C++ in Excel via COM\nNavier-Stokes with shaders"
  },
  {
    "objectID": "ideas.html#matematical-meanders",
    "href": "ideas.html#matematical-meanders",
    "title": "Future post ideas",
    "section": "",
    "text": "what is anomalous diffusion?\nhow to start learning maths?"
  },
  {
    "objectID": "ideas.html#divergent-paths",
    "href": "ideas.html#divergent-paths",
    "title": "Future post ideas",
    "section": "",
    "text": "Twists and turns of modern career"
  },
  {
    "objectID": "ideas.html#book-reviews",
    "href": "ideas.html#book-reviews",
    "title": "Future post ideas",
    "section": "",
    "text": "Fluent Python\nOut of Crisis"
  },
  {
    "objectID": "ideas.html#links",
    "href": "ideas.html#links",
    "title": "Future post ideas",
    "section": "",
    "text": "https://www.youtube.com/watch?v=uimdXPZc40I"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "bwrob blog",
    "section": "",
    "text": "This blog is a battleground of sorts, but instead of swords and shields, we wield the weapons of Python and C++. I’m a mathematician turned quantitative analyst turned software engineer. You can expect high standard deviation of topics here.\nHere, I’ll document my coding conquests, from building practical and impractical tools, exploring financial concepts, to playing around with physics simulations.\nExpect a healthy dose of humor alongside the technical discussions. Let’s be honest, even the most complex problems are more enjoyable with a sprinkle of laughter. So, grab a cup of coffee and join me on this exploration – even if it’s just for one interested reader!\n\n\n\n\n\n\n\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nExit stack to the rescue\n\n\n\nPythonic Distractions\n\n\nContext Managers\n\n\n\nHow to chain resource managers in elegant way.\n\n\n\nbwrob\n\n\nMay 12, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nStrategies for Numerical Integration\n\n\n\nPythonic Distractions\n\n\nDesign Patterns\n\n\n\nHow to apply strategy design pattern to decouple integration problem from method it’s solved with.\n\n\n\nbwrob\n\n\nApr 28, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWelcome To My Blog\n\n\n\nNews\n\n\n\nWarm welcome to enjoy the ride with me.\n\n\n\nbwrob\n\n\nApr 23, 2024\n\n\n\n\n\n\n\n\nNo matching items\n\n Back to top"
  },
  {
    "objectID": "pages/resume.html",
    "href": "pages/resume.html",
    "title": "Bartosz Wróblewski",
    "section": "",
    "text": "Mathematician at heart, quantitative finance technologist by trade. I leverage diverse experiences in academia, derivatives valuation, market risk, and quantitative development to bring a generalist’s perspective to quantitative finance and software engineering.\n\n \n  \n   \n  \n    \n     LinkedIn\n  \n  \n    \n     Github\n  \n  \n    \n     Contact"
  },
  {
    "objectID": "pages/resume.html#professional-experience",
    "href": "pages/resume.html#professional-experience",
    "title": "Bartosz Wróblewski",
    "section": "Professional Experience",
    "text": "Professional Experience\n\nSyberry\n\nFinancial Software Engineer | Sep 2023 - present\nDevelopment of a financial platform for a hedge fund client. Bridging the gap between hedge fund risk managers and software engineers.\nTechnologies\n\nBackend: Python, Dagster, FastAPI, Pytest, Pandas, NumPy, SQLAIchemy.\nDatabases: PostgreSQL.\nInfrastructure/pipelines: AWS, Terraform, Terraspace, Docker, GitHub Actions.\n\n\n\n\nBank of New York Mellon\n\nSenior Specialist, Model Development | Jul 2022 - Sep 2023\nMarket Risk Modelling team responsible for modeling of VaR and SVaR, comprehensive test scenarios and portfolio sensitivity exposures.\n\nDeveloping, maintaining and documenting models for pricing and market scenario generation (VaR, SVaR and stress testing).\nMaintaining and benchmarking vendor pricing models.\nDesigning, creating and analyzing risk-related reports and ad hoc analysis for business and management.\nResponsible for Market Risk RWA projections submission for CCAR 2023.\nCoordinating development projects with IT, Validation and Risk Managment.\n\nTechnologies\n\nInternal risk models: C++.\nVendor pricing system: Murex.\nDatabases: MS SQL.\nTooling: Python, Quantlib, VBA.\n\n\n\n\nCredit Suisse\n\nQuantitative Analyst | Nov 2018 - Jun 2022\nCredit Derivatives Modelling division, part of global QuantStrats department.\n\nDevelopment and maintenance of valuation and market data models.\nProviding direct support to Traders and the Middle Officein issues regarding valuation and risk.\nExtending and creating COM-addin based Excel pricing sheets used by Trading and Product Control.\nAssisting with calculation and analysis of risk profiles, PnL reports, transition impact assessments of trade portfolios.\nRepresented the company by giving lectures and taking part in campus recruitment programs.\n\nStructured Notes\nCredit Suisse issued structured note products (corporate bonds with derivatives attached to payout.)\n\nContributed to structured notes valuation model framework implemented in vectorized C++.\nUpdated credit curve models to be compatible with OIS discounting in preparation to LIBOR cessation.\n\nLongevity Derivatives\nLongevity-based (insurance policies and pension schemes) financial derivatives.\n\nMigrated existing legacy tools to 64-bit environment.\n\nTechnologies\n\nPricing framework: F#, C++, COM.\nRisk Managment: C#.\nTrading tools: Excel, VBA.\nCI/CD: Perforce, TeamCity."
  },
  {
    "objectID": "pages/resume.html#academic-experience",
    "href": "pages/resume.html#academic-experience",
    "title": "Bartosz Wróblewski",
    "section": "Academic Experience",
    "text": "Academic Experience\n\nUniversity of Wrocław\n\nPhD Candidate | Oct 2016 - Jan 2019\nResearching applications of functional and harmonic analysis to study of evolution equations involving non-local unbounded operators. Unfinished.\n\n\nJunior Researcher | Apr 2017 - Jan 2019\nParticipated in the Polish National Science Center research grant Nonlocal parabolic problems: regularity, blowup, pattern formation. Principal Investigator Prof. Piotr Biler.\n\n\nTeaching Assistant | Mar 2017 - Jul 2018\nNon-linear Functional Analysis, Ordinary Differential Equations, Honors Ordinary Differential Equations.\n\n\n\nUniversity of Warsaw\n\nResearch Intern | Dec 2016 - Mar 2017\nVisiting position during CrossFields PDEs semester organised and sponsored by The Simons Foundation.\nCollaboration with Raphael Dunchin Piotr B. Mucha and with Jan Peszek in the research on fractional Euler alignment system.\n\nRegular solutions to the fractional Euler alignment system in the Besov spaces framework published in Mathematical Models and Methods in Applied Sciences Vol. 29, No. 01, pp. 89-119\n\n\n\nTeaching Assistant | Jan 2017 - Mar 2017\nAnalysis 1, Analysis 2."
  },
  {
    "objectID": "pages/resume.html#education",
    "href": "pages/resume.html#education",
    "title": "Bartosz Wróblewski",
    "section": "Education",
    "text": "Education\n\nUniversity of Wrocław\n\nMsc in Theoretical Mathematics | Oct 2014 - Sep 2016\nThesis topic: “The anomalous diffusion and fractional Laplacian on the half-line” written under the supervision of Prof. Grzegorz Karch.\n\n\n\nWrocław University of Science and Technology\n\nBSc in Theoretical Mathematics | Oct 2011 - Jul 2014"
  },
  {
    "objectID": "pages/resume.html#personal-projects",
    "href": "pages/resume.html#personal-projects",
    "title": "Bartosz Wróblewski",
    "section": "Personal Projects",
    "text": "Personal Projects\n\nbwrob blog\nBlog on programming and finance. This blog is generated from .yaml and .qmd files using Quarto and deployed to GitHub Pages through Github Actions. To learn more see this post.\n\n\nxtb-sdk\nSoftware development kit for xStation API (xtb brokerage account). Allows for convenient fetching and persisting historical and live market data, trading and account management. Built with websockets, pydantic, pandera, docker… To learn more see this series of posts."
  },
  {
    "objectID": "posts/240426_welcome/index.html",
    "href": "posts/240426_welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in the bwrob blog. Welcome!\nThis blog is a battleground of sorts, but instead of swords and shields, we wield the weapons of Python and C++. I’m a mathematician turned quantitative analyst turned software engineer. You can expect high standard deviation of topics here.\nHere, I’ll document my coding conquests, from building practical and impractical tools, exploring financial concepts, to playing around with physics simulations.\nExpect a healthy dose of humor alongside the technical discussions. Let’s be honest, even the most complex problems are more enjoyable with a sprinkle of laughter. So, grab a cup of coffee and join me on this exploration – even if it’s just for one interested reader!\n\n\n\n Back to top"
  }
]