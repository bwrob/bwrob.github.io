[
  {
    "objectID": "ideas.html",
    "href": "ideas.html",
    "title": "Future post ideas",
    "section": "",
    "text": "see\n\n\n\n\n\nflowchart LR\n  A[Hard edge] --&gt; B(Round edge)\n  B --&gt; C{Decision}\n  C --&gt; D[Result one]\n  C --&gt; E[Result two]\n\n\n\n\n\n\n\n\n\n\n\nsequenceDiagram\n  participant Alice\n  participant Bob\n  Alice-&gt;&gt;John: Hello John, how are you?\n  loop Healthcheck\n    John-&gt;&gt;John: Fight against hypochondria\n  end\n  Note right of John: Rational thoughts &lt;br/&gt;prevail!\n  John--&gt;&gt;Alice: Great!\n  John-&gt;&gt;Bob: How about you?\n  Bob--&gt;&gt;John: Jolly good!\n\n\n\n\n\n\n\n\n\npython Windows startup script\nparallelize pandas apply\nimplied volatility function\nfast IV calculation on milions of options\nIntro to Python data model\n\n\n\n\n\nAncient way of satisfying your trader: C++ in Excel via COM\nNavier-Stokes with shaders\n\n\n\n\n\nwhat is anomalous diffusion?\nhow to start learning maths?\n\n\n\n\n\nTwists and turns of modern career\nWhat can a mathematics graduate do?\n\n\n\n\n\nLinux in Windows\nLinux terminal ultimate setup\n\n\n\n\n\nFluent Python\nOut of Crisis\n\n\n\n\n\nhttps://www.youtube.com/watch?v=uimdXPZc40I"
  },
  {
    "objectID": "ideas.html#pythonic-distractions",
    "href": "ideas.html#pythonic-distractions",
    "title": "Future post ideas",
    "section": "",
    "text": "python Windows startup script\nparallelize pandas apply\nimplied volatility function\nfast IV calculation on milions of options\nIntro to Python data model"
  },
  {
    "objectID": "ideas.html#lower-level",
    "href": "ideas.html#lower-level",
    "title": "Future post ideas",
    "section": "",
    "text": "Ancient way of satisfying your trader: C++ in Excel via COM\nNavier-Stokes with shaders"
  },
  {
    "objectID": "ideas.html#matematical-meanders",
    "href": "ideas.html#matematical-meanders",
    "title": "Future post ideas",
    "section": "",
    "text": "what is anomalous diffusion?\nhow to start learning maths?"
  },
  {
    "objectID": "ideas.html#divergent-paths",
    "href": "ideas.html#divergent-paths",
    "title": "Future post ideas",
    "section": "",
    "text": "Twists and turns of modern career\nWhat can a mathematics graduate do?"
  },
  {
    "objectID": "ideas.html#dev-setup",
    "href": "ideas.html#dev-setup",
    "title": "Future post ideas",
    "section": "",
    "text": "Linux in Windows\nLinux terminal ultimate setup"
  },
  {
    "objectID": "ideas.html#book-reviews",
    "href": "ideas.html#book-reviews",
    "title": "Future post ideas",
    "section": "",
    "text": "Fluent Python\nOut of Crisis"
  },
  {
    "objectID": "ideas.html#links",
    "href": "ideas.html#links",
    "title": "Future post ideas",
    "section": "",
    "text": "https://www.youtube.com/watch?v=uimdXPZc40I"
  },
  {
    "objectID": "posts/strategy_pattern_integration/index.html",
    "href": "posts/strategy_pattern_integration/index.html",
    "title": "Strategies for Numerical Integration",
    "section": "",
    "text": "Calculation of many financial methods or metrics relies on a mathematical tool called numerical integration. In simple terms, numerical integration takes a function that represents a continuous process (like the changing value of an investment over time) and approximates the area under its curve. This area can then be used to calculate important quantities, like the total return of the investment or price of a derivative instrument.\nSo we are tasked with a problem, and one that has many different ways of solving, or rather approximating the solution. You most likely (taking into account you’re still reading this) encountered rectangle rule, or Riemann summation in your Calculus 101 course/self-learning. But there are many other techniques, which we call schemes.\nFor quantitative analysts, the choice of the integration method matters. Different integration schemes offer varying levels of accuracy and efficiency. Unfortunately there’s no best technique. Same algorithm can be a perfect fit for problems with certain characteristics, but unusable for others. And then there is the old as time performance vs. accuracy trade-off.\nAs programmers working in finance, we need to be adaptable and leverage solutions that allow us to switch between these methods seamlessly."
  },
  {
    "objectID": "posts/strategy_pattern_integration/index.html#numerical-integration",
    "href": "posts/strategy_pattern_integration/index.html#numerical-integration",
    "title": "Strategies for Numerical Integration",
    "section": "",
    "text": "Calculation of many financial methods or metrics relies on a mathematical tool called numerical integration. In simple terms, numerical integration takes a function that represents a continuous process (like the changing value of an investment over time) and approximates the area under its curve. This area can then be used to calculate important quantities, like the total return of the investment or price of a derivative instrument.\nSo we are tasked with a problem, and one that has many different ways of solving, or rather approximating the solution. You most likely (taking into account you’re still reading this) encountered rectangle rule, or Riemann summation in your Calculus 101 course/self-learning. But there are many other techniques, which we call schemes.\nFor quantitative analysts, the choice of the integration method matters. Different integration schemes offer varying levels of accuracy and efficiency. Unfortunately there’s no best technique. Same algorithm can be a perfect fit for problems with certain characteristics, but unusable for others. And then there is the old as time performance vs. accuracy trade-off.\nAs programmers working in finance, we need to be adaptable and leverage solutions that allow us to switch between these methods seamlessly."
  },
  {
    "objectID": "posts/strategy_pattern_integration/index.html#design-patterns",
    "href": "posts/strategy_pattern_integration/index.html#design-patterns",
    "title": "Strategies for Numerical Integration",
    "section": "Design patterns",
    "text": "Design patterns\nThis is where design patterns come in. Design patterns are reusable solutions to common programming problems. Their widespread adoption in software development is largely attributed to the publication of Design Patterns: Elements of Reusable Object-Oriented Software in 1994. Authored by E. Gamma, R. Helm, R. Johnson, and J. Vlissides (often referred to as the “Gang of Four” or GoF), this book cataloged 23 essential software design patterns. These patterns provided solutions to common design problems in object-oriented programming, promoting code reusability, maintainability, and flexibility.\nSome design patterns can feel clunky or inelegant when implemented in Python. The language itself often has built-in features or idioms that achieve the same result in a more Pythonic way (meaning it follows Python’s style and conventions). Sometimes, design patterns can be seen as overcomplicating simple problems. On the other hand, usage of well-known and understood patterns may enhance your engineering skills and improve code readability.\nUltimately, the decision of whether or not to use design patterns in Python depends on the specific context of your project and your coding style. There’s no right or wrong answer. But first, you need to know the classics to diss the classics. We’ll hold on with the dissing for now, cause in the example below chosen design pattern makes for a very clean implementation. You’ll see for yourself."
  },
  {
    "objectID": "posts/strategy_pattern_integration/index.html#strategy-pattern",
    "href": "posts/strategy_pattern_integration/index.html#strategy-pattern",
    "title": "Strategies for Numerical Integration",
    "section": "Strategy pattern",
    "text": "Strategy pattern\nWe know the stage now — one problem statement, multiple strategies to tackle. Important observation here is that we don’t actually care which one is used. When you substitute the integral value to client code — a formula or further algorithm — it’s irrelevant how it was computed, as long its correct to required level of accuracy. This means that the problem should be decoupled from algorithms to solve it. We should target a implementation where you can state a problem Calculate the integral of \\(\\sin(x)\\) from \\(0\\) to \\(\\pi\\) and then just throw different algorithms at it to obtain a solution. So let’s get coding!\n\n\n\n\n\n\nNote\n\n\n\nI will show you this pattern through an example. If you prefer more generic setup see Refactoring Guru’s implementation. The customary ‘software engineering’ example used to present the SDP is sorting a list of integers using different sorting algorithms."
  },
  {
    "objectID": "posts/strategy_pattern_integration/index.html#abstract-schema",
    "href": "posts/strategy_pattern_integration/index.html#abstract-schema",
    "title": "Strategies for Numerical Integration",
    "section": "Abstract schema",
    "text": "Abstract schema\nEach scheme that we’d come up with, even the most complex ones, would have the same main purpose — ‘integrate’. To make the implementation for it, we create a template class that all concrete schemes will inherit from.\n\nfrom abc import ABC, abstractmethod\nfrom typing import Callable\n\nclass IntegrationScheme(ABC):\n    \"\"\"Abstract base class for integration schemas.\"\"\"\n\n    @abstractmethod\n    def integrate(\n        self,\n        integrand: Callable[[float], float],\n        *,\n        start: float,\n        end: float,\n    ) -&gt; float:\n        \"\"\"Abstract method for integrating a function.\"\"\"\n\nUnpacking this, we already used some nifty Pythonic tricks in those few lines:\n\nABC is a way of defining abstract classes. If you try to create an object of a class inheriting from ABC you’d get an error. It is used as a base class for concrete subclasses and serves as a template. Think of an example of animal and cat from the real world. You’ve never seen an abstract animal being in your life (that would be a truly transcendental experience). But you’ve hopefully seen many cats.\nDecorator @abstractmethod signifies that the method is just a mock-up. It needs to be present and overridden in all concrete classes that inherit from IntegrationScheme\nType annotations like start: float don’t affect the script behavior in any way. Those are only for us to not get lost in Python’s dynamic typing magic. They can also be leveraged by static type checkers like mypy to flag problems with your code before you run it — just like in compiled languages.\nCallable annotation signifies a function-like object something you can call through (), like some_func(one, second=two)’ — here some_func is a callable. Calls to an object can be implemented by writing the __call__ method for the class."
  },
  {
    "objectID": "posts/strategy_pattern_integration/index.html#concrete-schema-implementations",
    "href": "posts/strategy_pattern_integration/index.html#concrete-schema-implementations",
    "title": "Strategies for Numerical Integration",
    "section": "Concrete schema implementations",
    "text": "Concrete schema implementations\n\nRectangle Rule\nIt’s the simplest way of estimating the area under a curve you can think of — cover it with smaller and smaller rectangles with the value of a function at the leftmost point as height constant width.\n\nImplementing this idea is trivial when using numpy, but let’s add some syntactic sugar so the class is sweeter to work with.\n\nimport numpy as np\n\nclass RectangleScheme(IntegrationScheme):\n    \"\"\"Schema for rectangle integration.\"\"\"\n\n    def __init__(\n        self,\n        steps: int,\n    ) -&gt; None:\n        \"\"\"Initializes the rectangle integration config.\"\"\"\n        if steps &lt;= 0:\n            raise ValueError(\"Steps must be greater than 0.\")\n        self._steps = steps\n\n    def __str__(self) -&gt; str:\n        \"\"\"Returns the string representation of the schema.\"\"\"\n        return f\"Rectangle schema with {self._steps} steps\"\n\n    def integrate(\n        self,\n        integrand: Callable[[float], float],\n        *,\n        start: float,\n        end: float,\n    ) -&gt; float:\n        \"\"\"Integrates a function using rectangle integration.\"\"\"\n        x_points = np.linspace(start, end, self._steps)\n        values = integrand(x_points)\n        dx = (end - start) / np.float64(self._steps)\n        return np.sum(values) * dx\n\n\nRectangleScheme subclasses IntegrationScheme so we need to implement the integrate method.\n__init__ method is run each time object of this class is requested. It sets the stage — in this case all we need is the number of rectangles we are to use. To be cautious, we check if the steps number is positive.\n__str__ is called when we try to represent the object as string — ex. in f-strings or directly calling str(). We just taught our class objects to introduce themselves nicely.\nintegrate is as simple as the idea behind it:\n\nget the equaly spaced x values,\ncalculate integrand values at the points,\nsum it up,\nmultiply the sum by the distance between two consecutive points.\n\n\n\n\nSimple Monte Carlo\nThis guy sounds fancy with its luxurious Monaco vibes, but it’s just a peasant in a nice suit. Instead of looking at equaly-spaced points, we shuffle them from uniform distribution on the interval of integration. We calculate the integrand function values at those points and sum them up. Then multiply the sum by the average distance between points and through the magic of probability theory (and not opening actual probability textbook in 10 years) you get a good probabilistic estimator of the integral value. The implementation is analogous to the RectangleScheme.\n\nfrom typing import Optional\n\nclass MonteCarloScheme(IntegrationScheme):\n    \"\"\"Schema for Monte Carlo integration.\"\"\"\n\n    def __init__(\n        self,\n        random_points: int,\n        random_seed: Optional[int] = None,\n    ) -&gt; None:\n        \"\"\"Initializes the rectangle integration config.\"\"\"\n        if random_points &lt;= 0:\n            raise ValueError(\"Points must be greater than 0.\")\n        self.__random_points = random_points\n        self.__random_seed = random_seed\n\n    def __str__(self) -&gt; str:\n        \"\"\"Returns the string representation of the schema.\"\"\"\n        points_msg = f\"Monte Carlo schema with {self.__random_points} random points\"\n        seed_msg = f\" and seed {self.__random_seed}\" if self.__random_seed else \"\"\n        return f\"{points_msg}{seed_msg}\"\n\n    def integrate(\n        self,\n        integrand: Callable[[float], float],\n        *,\n        start: float,\n        end: float,\n    ) -&gt; float:\n        \"\"\"Integrates a function using Monte Carlo integration.\"\"\"\n        np.random.seed(seed=self.__random_seed)\n        x_points = np.random.uniform(start, end, self.__random_points)\n        values = integrand(x_points)\n        average_dx = (end - start) / np.float64(self.__random_points)\n        return np.sum(values) * average_dx\n\n\nOptional[int] annotation means that the value of random_seed can be a float or None. With a set seed we get a reproducable results — good for testing but not for actual usage. Hence the default value here is None.\n\n\n\n\n\n\n\nNote\n\n\n\nThe Optional stands for could be None as well, it doesn’t affect if the input is mandatory or not. In our case it’s not, but thats stated by the = None part. In Python 3.11 onwards it’s recommended to use int | None instead."
  },
  {
    "objectID": "posts/strategy_pattern_integration/index.html#integrator",
    "href": "posts/strategy_pattern_integration/index.html#integrator",
    "title": "Strategies for Numerical Integration",
    "section": "Integrator",
    "text": "Integrator\nWhat’s left is to have a way of defining the problem to solve and define how our schemes (strategies) interact with it.\n\n\"\"\"An integrator class that allows to perform integration using different schemas.\"\"\"\nfrom typing import Callable\n\nclass Integrator:\n    \"\"\"An integrator class that allows to perform integration using different\n    schemas as strategies.\"\"\"\n\n    def __init__(\n        self,\n        integrand: Callable[[float], float],\n        interval_start: float,\n        interval_end: float,\n    ) -&gt; None:\n        \"\"\"Initializes the integrator class.\"\"\"\n        if interval_start &gt;= interval_end:\n            raise ValueError(\"Start value must be less than end value.\")\n        self.__integrand = integrand\n        self.__interval_start = interval_start\n        self.__interval_end = interval_end\n\n    def __call__(\n        self,\n        schema: IntegrationScheme,\n    ) -&gt; float:\n        \"\"\"\n        Calculates the definite integral value of a function.\n\n        Args:\n            schema: integration schema\n        \"\"\"\n        print(f\"Using {schema}.\")\n        return schema.integrate(\n            self.__integrand,\n            start=self.__interval_start,\n            end=self.__interval_end,\n        )\n\n\nThe __init__ takes in the obvious parameters — function to integrate, start and end of the interval. It also checks if it’s a proper integral.\nWe get to implement our own __call__ method now. It’s clear what Integrator class does. No need to have a method with a descriptive name like Integrator.integrate. To use it you pass through the integration scheme into the integrator — notice annotation of the abstract IntegrationScheme. It prints the info on strategy used (using the __str__ methods) and calls integrate method of the scheme. No care in the world on how the value is actually calculated."
  },
  {
    "objectID": "posts/strategy_pattern_integration/index.html#lets-integrate",
    "href": "posts/strategy_pattern_integration/index.html#lets-integrate",
    "title": "Strategies for Numerical Integration",
    "section": "Let’s integrate!",
    "text": "Let’s integrate!\nOk, now to the integrating! Let’s set up the stage:\n\nstart, end = 0, np.pi / 2.0\n\ndef f(x: float) -&gt; float:\n    return np.sin(x) + np.cos(x)\n\nExcited? Don’t be… yet.\nWe should get some benchmark value first. As none of us would bother to integrate this by hand, we’ll use SciPy. Unexpectedly (SciPy uses C and Fortran underneath), we get the result in a breeze and it is very close to actual value of 2.0.\n\nfrom scipy.integrate import quad\n\nscipy_quad, err = quad(f, start, end)\nprint(scipy_quad)\n\n1.9999999999999998\n\n\nNow let’s use our Integrator class and see.\n\nintegrator = Integrator(\n    f,\n    interval_start=start,\n    interval_end=end,\n)\n\niterations = [2**i for i in range(0,21,5)]\nrectangle_results = [integrator(RectangleScheme(steps=i)) for i in iterations]\nmc_results = [integrator(MonteCarloScheme(random_points=i)) for i in iterations]\n\nprint(f\"Rectangle schema results:\\n{rectangle_results}.\")\nprint(f\"Monte Carlo schema results:\\n{mc_results}.\")\n\nUsing Rectangle schema with 1 steps.\nUsing Rectangle schema with 32 steps.\nUsing Rectangle schema with 1024 steps.\nUsing Rectangle schema with 32768 steps.\nUsing Rectangle schema with 1048576 steps.\nUsing Monte Carlo schema with 1 random points.\nUsing Monte Carlo schema with 32 random points.\nUsing Monte Carlo schema with 1024 random points.\nUsing Monte Carlo schema with 32768 random points.\nUsing Monte Carlo schema with 1048576 random points.\nRectangle schema results:\n[np.float64(1.5707963267948966), np.float64(1.986172817555692), np.float64(1.9995804632216618), np.float64(1.9999869013603688), np.float64(1.9999995906791057)].\nMonte Carlo schema results:\n[np.float64(1.7178759835606303), np.float64(2.00427661768383), np.float64(2.0149511903403177), np.float64(1.9994117041535224), np.float64(1.9999757179859985)].\n\n\nThe performance and convergence of those schemes is terrible. Like anything in Python, if you want robust and performing code, you need to implement it with C or use any/all of the enhancement frameworks that Python provides (see Numba). Additionally, the simple methods we implemented are very naive. The standard numerical packages use sophisticated algorithms honed for many decades.\nBut I was wrong! You should be excited! We just learned new approach for setting up extensible and readable code! Look how cleanly the problem statement is separated form different strategies to solve it.\nIf you are now wondering how much we could improve by using more advanced techniques (like stratified Monte Carlo or adaptive quadrature) you just need to implement new subclass of `IntegrationSchema’ and you’re done. No changes to the existing code are needed, just simple extension. And that’s the idea behind strategy pattern.\n\n\n\n\n\n\nNote\n\n\n\nDownload the whole code here."
  },
  {
    "objectID": "posts/exit_stack/index.html",
    "href": "posts/exit_stack/index.html",
    "title": "Exit stack to the rescue",
    "section": "",
    "text": "As a quantitative finance professional you’ll often find yourself with risk management systems (RMS). RMS’s are extensive frameworks that let you properly define a book (portfolio) of your financial transactions and run varia of pricing and risk analysis on it. For big financial players, like investment banks, the RMS will be internal proprietary codbase that is run in-house. For smaller enterprises or second-line reporting it’s not feasable to tackle creating such vast infrastructure. Hence, where there’s a need, someone will try to make money on it. This leads us to third-party (or vendor) RMS, of which there are plenty (ex. Murex, Acadia).\nWorking with vendor RMS, especially one that covers computations for you, entails juggling multiple resources to obtain your risk metrics. Defining OTC products, benchmarks, portfolios, and running risk analysis can involve numerous API calls, each requiring proper setup and cleanup. This can lead to messy code and potential errors or performance bottlenecks if resources aren’t handled correctly.\nThankfully, Python provides a powerful concept called context managers (CM) that streamline resource managment. True to the language’s ‘batteries included’ philosophy, there’s also a contextlib library that contains variety of tools for easing up your work with CMs. Today we’ll look at a (mock-up) usage of ExitStack class in real-life scenario of running risk analysis on RMS. If you need a refresher on CMs, check out this tutorial by RealPython."
  },
  {
    "objectID": "posts/exit_stack/index.html#working-with-risk-managment-systems",
    "href": "posts/exit_stack/index.html#working-with-risk-managment-systems",
    "title": "Exit stack to the rescue",
    "section": "",
    "text": "As a quantitative finance professional you’ll often find yourself with risk management systems (RMS). RMS’s are extensive frameworks that let you properly define a book (portfolio) of your financial transactions and run varia of pricing and risk analysis on it. For big financial players, like investment banks, the RMS will be internal proprietary codbase that is run in-house. For smaller enterprises or second-line reporting it’s not feasable to tackle creating such vast infrastructure. Hence, where there’s a need, someone will try to make money on it. This leads us to third-party (or vendor) RMS, of which there are plenty (ex. Murex, Acadia).\nWorking with vendor RMS, especially one that covers computations for you, entails juggling multiple resources to obtain your risk metrics. Defining OTC products, benchmarks, portfolios, and running risk analysis can involve numerous API calls, each requiring proper setup and cleanup. This can lead to messy code and potential errors or performance bottlenecks if resources aren’t handled correctly.\nThankfully, Python provides a powerful concept called context managers (CM) that streamline resource managment. True to the language’s ‘batteries included’ philosophy, there’s also a contextlib library that contains variety of tools for easing up your work with CMs. Today we’ll look at a (mock-up) usage of ExitStack class in real-life scenario of running risk analysis on RMS. If you need a refresher on CMs, check out this tutorial by RealPython."
  },
  {
    "objectID": "posts/exit_stack/index.html#setting-the-stage",
    "href": "posts/exit_stack/index.html#setting-the-stage",
    "title": "Exit stack to the rescue",
    "section": "Setting the stage",
    "text": "Setting the stage\nTo run an analysis, the RMS first needs to know what our positions are. In case of tradable assets it’s simple — we provide a market identifier and how much of the instrument we are holding. What do we do if we have some bespoke agreement with specific counterparty (an over-the-counter transaction)? We will need to define it from scratch in the RMS using data from the term sheet (assuming this kind of agreement is covered).\nNext, we need to specify the risk metrics we want to calculate — define the analysis scope. Let’s say we hold some equity options and we are intertested in their deltas and beta exposures. The betas are defined with respect to some benchmark — ex. portfolio holding 1 stock in US500 ETF. So we define the benchmark and link it to our analysis.\nFinally — once portfolio and analysis are defined in RMS — we call the API to start the calculation and respond with results. This is the control flow we execute to get to this point:\n\n\n\n\n\nflowchart LR\n  A[OTC Products] --&gt; B[Portfolio]\n  B --&gt; C{Analysis Run}\n  D[Benchmarks] --&gt; E[Analysis Definition]\n  E --&gt; C\n  C --&gt; F(Results)\n\n\n\n\n\n\nIf we know we’re never going to use all of the resources, we should clean up the server artifacts after receving the results. So for each resource we should have a CM.\n\nMock functions\nThe setup described above comes from a real-life situation I worked through. I can’t show you the actual API usage or data (or even the name of RMS itself), so we need to define some mocker functions. Mocks like this are actually not an uncommon thing — such approach is prevalent in testing API client code. In our case it would look like this:\n\nfrom enum import StrEnum\nfrom uuid import uuid4\n\n\nclass MockObject(StrEnum):\n    \"\"\"Types of mock objects.\"\"\"\n\n    ANALYSIS = \"analysis\"\n    BENCHMARK = \"benchmark\"\n    OTC_PRODUCTS = \"otc_products\"\n    PORTFOLIO = \"portfolio\"\n\n\ndef mock_object(object_type: MockObject) -&gt; str:\n    \"\"\"Mock a UUID for a given object type.\n\n    Args:\n        object_type: Type of object.\n    \"\"\"\n    return f\"{object_type}_{uuid4()}\"\n\n\ndef mock_preparation(object_type: MockObject, **kwargs) -&gt; None:\n    \"\"\"Mock preparation of an object.\n\n    Args:\n        object_type: Type of object.\n    \"\"\"\n    print(f\"Preparing {object_type}\" + (f\" using {kwargs}\" if kwargs else \".\"))\n\n\ndef mock_clean_up(object_uuid: str) -&gt; None:\n    \"\"\"Mock clean up of an object.\n\n    Args:\n        object_uuid: Uuid of the object.\n    \"\"\"\n    print(f\"Cleaning up after {object_uuid}.\")\n\nFor each of the four types of resources we mock the preparation, object (ex. API response, some id of definition on server) and the clean up process.\n\n\nContext managers\nEasiest way to define a CM is through contextlib.contextmanager decorator. To use it, you need a function that returns a generator. Code executed on enter should come before yield statement and the one for the exit afterwards. The generator yields the result of the CM (ex. handle to an opened file), the y in with x(*args) as y:.\n\nfrom contextlib import contextmanager\nfrom typing import Generator\n\n@contextmanager\ndef analysis(\n    *,\n    benchmark_uuid: str,\n) -&gt; Generator[str, None, None]:\n    \"\"\"Mock definition of an analysis.\n\n    Example: equity delta and correlation with benchmark.\n\n    Args:\n        benchmark_uuid: Uuid of the benchmark.\n    \"\"\"\n    mock_preparation(\n        MockObject.ANALYSIS,\n        benchmark_name=benchmark_uuid,\n    )\n    analysis_uuid = mock_object(MockObject.ANALYSIS)\n    yield analysis_uuid\n    mock_clean_up(analysis_uuid)\n\nModern approach to Python development leans heavily towards type annotations. Dynamical typing is powerful but can lead to unwieldy code. To properly annotate the analysis function we need to import Generator from typing module. Remember, the @contextmanager decorator takes the function and turns it into CM — a class with __enter__ and __exit__ methods. The Generator needs three inputs but in our case only the first one is important — YieldType, here str (see for more).\nWith this done implementing the 3 remaining CMs is easy, just remember our flow chart.\n\n@contextmanager\ndef benchmark() -&gt; Generator[str, None, None]:\n    \"\"\"Mock definition of a benchmark.\n\n    Args:\n        otc_products_uuid: Uuid of the otc products.\n    \"\"\"\n    mock_preparation(\n        MockObject.BENCHMARK,\n    )\n    benchmark_uuid = mock_object(MockObject.BENCHMARK)\n    yield benchmark_uuid\n    mock_clean_up(benchmark_uuid)\n\n\n@contextmanager\ndef otc_products() -&gt; Generator[str, None, None]:\n    \"\"\"Mock definition of an otc products.\n\n    Args:\n        otc_products_uuid: Uuid of the otc products.\n    \"\"\"\n    mock_preparation(MockObject.OTC_PRODUCTS)\n    otcs_uuid = mock_object(MockObject.OTC_PRODUCTS)\n    yield otcs_uuid\n    mock_clean_up(otcs_uuid)\n\n\n@contextmanager\ndef portfolio(\n    *,\n    portfolio_name: str,\n    otc_products_uuid: str,\n) -&gt; Generator[str, None, None]:\n    \"\"\"Mock definition of a portfolio.\n\n    Args:\n        otc_products_uuid: Uuid of the otc products.\n    \"\"\"\n    mock_preparation(\n        MockObject.PORTFOLIO,\n        portfolio_name=portfolio_name,\n        otc_products_uuid=otc_products_uuid,\n    )\n    portfolio_uuid = mock_object(MockObject.PORTFOLIO)\n    yield portfolio_uuid\n    mock_clean_up(portfolio_uuid)\n\n\n\nAnalysis results\nNo stress or complexity here, to run the analysis we need to specify which analysis to run on which portfolio.\n\nimport pandas as pd\n\ndef analysis_results(\n    *,\n    analysis_uuid: str,\n    portfolio_uuid: str,\n) -&gt; pd.DataFrame:\n    \"\"\"Mock running the analysis on a given portfolio.\n\n    Returns empty dataframe.\n\n    Args:\n        analysis_uuid: Uuid of the analysis.\n        portfolio_uuid: Uuid of the portfolio.\n    \"\"\"\n    print(f\"Running analysis {analysis_uuid} on portfolio {portfolio_uuid}.\")\n    return pd.DataFrame()"
  },
  {
    "objectID": "posts/exit_stack/index.html#section",
    "href": "posts/exit_stack/index.html#section",
    "title": "Exit stack to the rescue",
    "section": "",
    "text": "Finally, we can run some (mock) risk analysis!\n\nUsing contexts directly\nFirst, we use the managers directly through with clause, remembering the dependencies from our flow chart.\n\nPORTFOLIO = \"portfolio_1\"\n\ndef run_analysis() -&gt; pd.DataFrame:\n    \"\"\"Mock running the analysis using with clauses.\"\"\"\n    with otc_products() as otc_uuid:\n        with benchmark() as benchmark_uuid:\n            with portfolio(\n                portfolio_name=PORTFOLIO,\n                otc_products_uuid=otc_uuid,\n            ) as portfolio_uuid:\n                with analysis(\n                    benchmark_uuid=benchmark_uuid,\n                ) as analysis_uuid:\n                    results = analysis_results(\n                        analysis_uuid=analysis_uuid,\n                        portfolio_uuid=portfolio_uuid,\n                    )\n    return results\n\nThis is terrible! I am already getting lost, needed few tries to get it right. We ended up with 6 levels of indentation, the code is confusing, the flow is obtuse. Let’s run it either way, to see if at least works.\n\ndef print_title(title: str) -&gt; None:\n    \"\"\"Print a title padded, surrounded by dashes and empty lines.\"\"\"\n    print(\"\\n\" + title.center(60, \"-\") + \"\\n\")\n\nprint_title(\"Running analysis.\")\nrun_analysis()\n\n\n---------------------Running analysis.----------------------\n\nPreparing otc_products.\nPreparing benchmark.\nPreparing portfolio using {'portfolio_name': 'portfolio_1', 'otc_products_uuid': 'otc_products_ab94967b-57b8-4c42-850a-279e96aa4352'}\nPreparing analysis using {'benchmark_name': 'benchmark_71275e95-c56f-464f-911c-5f993c20c18c'}\nRunning analysis analysis_969a4a02-db5b-4b70-8c05-0c837925720d on portfolio portfolio_f69291a9-ca2d-4b15-87c6-09b1c85b4bd4.\nCleaning up after analysis_969a4a02-db5b-4b70-8c05-0c837925720d.\nCleaning up after portfolio_f69291a9-ca2d-4b15-87c6-09b1c85b4bd4.\nCleaning up after benchmark_71275e95-c56f-464f-911c-5f993c20c18c.\nCleaning up after otc_products_ab94967b-57b8-4c42-850a-279e96aa4352.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGreat, the behaviour is as expected, everything is cleaned after nicely. We achieved the goal but the code is unmaintainable. Looks like a subject of the joke “good code makes your job safe for a day, but terrible code in production makes it safe for a lifetime”. Being reckless and with no regard to job security as we are, we’ll fix it.\nI can clearly recall the most unamanagable and unreadable code I’ve seen in my career and the culprit was fired in the end. Different reasons, long time later, but still. So the joke is just a joke, don’t rely on a bad code as your job insurance."
  },
  {
    "objectID": "posts/exit_stack/index.html#the-exitstack",
    "href": "posts/exit_stack/index.html#the-exitstack",
    "title": "Exit stack to the rescue",
    "section": "The ExitStack",
    "text": "The ExitStack\nHere comes in the MVP — ExitStack from contextlib, made for streamlining complex context managment situationships. Conceptually it’s just a First-In-Last-Out (FILO) stack. You put CMs on top, one by one. When CM is pushed to stack, its __enter__ method is called and you can intercept the result. ExitStack is a CM itself, it’s __exit__ method is just calling the exits of CMs in reverse order.\n\n\n\n\n\nflowchart LR\n    A(Enter CM A) ---&gt; B(Enter CM B)\n    B ---&gt; C(Enter CM C)\n    C ---&gt; D[Do stuff]\n    D ---&gt; E(Exit CM C)\n    E ---&gt; F(Exit CM B)\n    F ---&gt; G(Exit CM A)\n    A -.- G\n    B -.- F\n    C -.- E\n\n\n\n\n\n\n\nSo the flow is exactly the same as in our first attempt. Let’s try it!\n\nfrom contextlib import ExitStack\n\ndef run_analysis_with_exit_stack() -&gt; None:\n    \"\"\"Mock running the analysis using exit stack.\"\"\"\n    with ExitStack() as stack:\n        otc_uuid = stack.enter_context(otc_products())\n        benchmark_uuid = stack.enter_context(benchmark())\n        portfolio_uuid = stack.enter_context(\n            portfolio(\n                portfolio_name=PORTFOLIO,\n                otc_products_uuid=otc_uuid,\n            )\n        )\n        analysis_uuid = stack.enter_context(\n            analysis(\n                benchmark_uuid=benchmark_uuid,\n            )\n        )\n        results = analysis_results(\n            analysis_uuid=analysis_uuid,\n            portfolio_uuid=portfolio_uuid,\n        )\n\nThat’s amazing (if the approach works)! In our code we end up with only single with clause and the outputs of CMs are defined just like the regular variables. We just need to wrap the CM calls in stack.enter_context method that pushes each CM to the stack.\n\nprint_title(\"Running analysis with exit stack.\")\nrun_analysis_with_exit_stack()\n\n\n-------------Running analysis with exit stack.--------------\n\nPreparing otc_products.\nPreparing benchmark.\nPreparing portfolio using {'portfolio_name': 'portfolio_1', 'otc_products_uuid': 'otc_products_333fcd8a-4b2f-4d25-8523-86857d3c5186'}\nPreparing analysis using {'benchmark_name': 'benchmark_7da1d959-9f6c-48f8-98d4-4ded0eb5875e'}\nRunning analysis analysis_019cc57f-9eb2-49d9-87e0-dcc24f9a1b74 on portfolio portfolio_1163574f-acfe-4af0-9636-a983381ada7d.\nCleaning up after analysis_019cc57f-9eb2-49d9-87e0-dcc24f9a1b74.\nCleaning up after portfolio_1163574f-acfe-4af0-9636-a983381ada7d.\nCleaning up after benchmark_7da1d959-9f6c-48f8-98d4-4ded0eb5875e.\nCleaning up after otc_products_333fcd8a-4b2f-4d25-8523-86857d3c5186.\n\n\nIt works as well! We also get a package of benefits for free.\n\nDisabling the clean up\nWorking with API is tricky and debugging could be a painful experience. If we notice something iffy with the results we are reciving, it could be due to a bug at any of the stages. In such case disabling the artifact clean up and examining them is a good way to investigate. How do we do that? Comment out the exit code in our resource CMs? Nope, now we know better. With exit stack approach we just need to clean up the stack before exiting its context.\n\ndef run_analysis_with_exit_stack(\n    clean_up: bool = True,\n) -&gt; None:\n    \"\"\"Mock running the analysis using exit stack.\n\n    Args:\n        clean_up: Whether to clean up after the objects.\n    \"\"\"\n\n    with ExitStack() as stack:\n        otc_uuid = stack.enter_context(otc_products())\n        benchmark_uuid = stack.enter_context(benchmark())\n        portfolio_uuid = stack.enter_context(\n            portfolio(\n                portfolio_name=PORTFOLIO,\n                otc_products_uuid=otc_uuid,\n            )\n        )\n        analysis_uuid = stack.enter_context(\n            analysis(\n                benchmark_uuid=benchmark_uuid,\n            )\n        )\n        results = analysis_results(\n            analysis_uuid=analysis_uuid,\n            portfolio_uuid=portfolio_uuid,\n        )\n\n        if not clean_up:\n            _ = stack.pop_all()\n    return results\n\nThe _ = some_function() is a Pythonic way of disregarding outputs of some_function. Method pop_all actually moves the stack contents to a new stack, but we don’t care about that. We just want to get rid of them from our current one.\n\nprint_title(\"Running analysis with exit stack and no clean up.\")\nrun_analysis_with_exit_stack(clean_up=False)\n\n\n-----Running analysis with exit stack and no clean up.------\n\nPreparing otc_products.\nPreparing benchmark.\nPreparing portfolio using {'portfolio_name': 'portfolio_1', 'otc_products_uuid': 'otc_products_14d1af00-ae05-444f-a900-29aaa9d636bd'}\nPreparing analysis using {'benchmark_name': 'benchmark_af41bef5-2b80-4468-be0b-66edf122d7cf'}\nRunning analysis analysis_5a5b9ab1-7794-4de9-b467-f52cd7b9a8ed on portfolio portfolio_ea70e17b-a3a7-487a-a103-f75caa8c5a59.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMultiple portfolios\nBenefit #2 — what do we do if we have multiple managers and many portfolios to re-run for? Or — outside of the example scope — we want to held multiple files open at the same time? Easy, we just push to the stack in a loop or a list comprehension.\n\nPORTFOLIOS = [\"portfolio_1\", \"portfolio_2\", \"portfolio_3\"]\n\ndef run_analysis_with_exit_stack(clean_up: bool = True):\n    \"\"\"Mock running the analysis for multiple portfolios using exit stack.\n\n    Args:\n        clean_up: Whether to clean up after the objects.\n    \"\"\"\n    with ExitStack() as stack:\n        otc_uuid = stack.enter_context(otc_products())\n        benchmark_uuid = stack.enter_context(benchmark())\n        portfolio_uuids = [\n            stack.enter_context(\n                portfolio(\n                    portfolio_name=portfolio_name,\n                    otc_products_uuid=otc_uuid,\n                )\n            )\n            for portfolio_name in PORTFOLIOS\n        ]\n        analysis_uuid = stack.enter_context(\n            analysis(\n                benchmark_uuid=benchmark_uuid,\n            )\n        )\n        result_parts = [\n            analysis_results(\n                analysis_uuid=analysis_uuid,\n                portfolio_uuid=portfolio_uuid,\n            )\n            for portfolio_uuid in portfolio_uuids\n        ]\n        results = pd.concat(result_parts)\n\n        if not clean_up:\n            _ = stack.pop_all()\n    return results\n\nprint_title(\"Running analysis with exit stack on multiple portfolios.\")\nrun_analysis_with_exit_stack(clean_up=True)\n\n\n--Running analysis with exit stack on multiple portfolios.--\n\nPreparing otc_products.\nPreparing benchmark.\nPreparing portfolio using {'portfolio_name': 'portfolio_1', 'otc_products_uuid': 'otc_products_ffd6691b-2dbd-4d6d-bc02-650aeb364d85'}\nPreparing portfolio using {'portfolio_name': 'portfolio_2', 'otc_products_uuid': 'otc_products_ffd6691b-2dbd-4d6d-bc02-650aeb364d85'}\nPreparing portfolio using {'portfolio_name': 'portfolio_3', 'otc_products_uuid': 'otc_products_ffd6691b-2dbd-4d6d-bc02-650aeb364d85'}\nPreparing analysis using {'benchmark_name': 'benchmark_eabed5da-5cda-40f7-98e2-1ebd58b8e5ed'}\nRunning analysis analysis_2171bb0f-fce0-4674-b958-47a6967b5342 on portfolio portfolio_2bd5b49e-e033-4056-915b-86e5d022ccee.\nRunning analysis analysis_2171bb0f-fce0-4674-b958-47a6967b5342 on portfolio portfolio_497a987e-b596-4e9b-87db-6c7835aa11f6.\nRunning analysis analysis_2171bb0f-fce0-4674-b958-47a6967b5342 on portfolio portfolio_2c70b424-cf40-47af-b770-6552386f88d4.\nCleaning up after analysis_2171bb0f-fce0-4674-b958-47a6967b5342.\nCleaning up after portfolio_2c70b424-cf40-47af-b770-6552386f88d4.\nCleaning up after portfolio_497a987e-b596-4e9b-87db-6c7835aa11f6.\nCleaning up after portfolio_2bd5b49e-e033-4056-915b-86e5d022ccee.\nCleaning up after benchmark_eabed5da-5cda-40f7-98e2-1ebd58b8e5ed.\nCleaning up after otc_products_ffd6691b-2dbd-4d6d-bc02-650aeb364d85."
  },
  {
    "objectID": "posts/exit_stack/index.html#conclusion",
    "href": "posts/exit_stack/index.html#conclusion",
    "title": "Exit stack to the rescue",
    "section": "Conclusion",
    "text": "Conclusion\nToday we’ve learnt a new Python tool and seen an example of how quantitative developer might set up risk reporting job on vendor RMS. Sound like a very niche and unlikely situation for you? Maybe. But the moral here is to go and explore the Python standard library. Without using any additional packages we improved readability and flexibility of our initial attempt. Python really has ‘batteries included’, see for yourself!\n\n\n\n\n\n\nNote\n\n\n\nDownload the whole code here."
  },
  {
    "objectID": "pages/hobbies.html",
    "href": "pages/hobbies.html",
    "title": "Fueling the Mind & Body: My Off-Duty Explorations.",
    "section": "",
    "text": "Supprisingly, I still have some hobbies outside technology and finance. This list is meant to be aspirational – i.e. sort of Instagram take on my interests to motivate me to invest more time into things I like. Too often I find myself in a work-sleep-work cycle that leaves little time for enjoyment.\n\n\nI have a PS5, a NS and a gaming PC. I play only single-player games, enjoy rouge-likes and open-worlds the most. My favorite games are God of War (2018), Hades and Trackmania. If your life’s companion is also a gamer (or just plays a little bit) i highly recommend It Takes Two.\n\n\n\n\nGot two cameras, old big hog Canon 450D and compact and sleek Sony A6000. I can make a decent portrait or Instagram ‘location photo’ but mosty interested in nature and urban settings. Would like to learn more on light and exposure usage, for now I am looking for contrasts and interesting compositions in my photos.\n\n\n\n\nClever ideas that fill and fuel natural sciences are often intimidating. Sure, there are occasional outliers – genius individuals that make history with revolutionary inventions. But most of the progress is achieved by a tectonic creep of incremental small wins and observations. All of those geniuses stood on the shoulders of giants that came before. The history of how those ideas and meanders of knowledge happened can be thrilling and educating.\n\n\n\n\nMaster chef of making tasty meal from leftovers. Specializing in Asian fusion cuisine. Fried rice with pulled tofu? Sushi with beetroot? Korean beef with sauerkraut? Yes, those are all delicious!\n\n\n\n\nI am a proud owner of 90’s vintage road bike. It was recently refurbished and looks smashing! It even has chipset print and binary code on the handles (photo pre-renovation)!\n\n\n\n\nYes, just strolling, but with a philosophy. No headphones, no distractions, no direction. Just observing what changed in the neighborhood I’ve lived in for the last 15 years, and what is happening inside. Think awareness meditation but while walking."
  },
  {
    "objectID": "pages/hobbies.html#road-cycling",
    "href": "pages/hobbies.html#road-cycling",
    "title": "Fueling the Mind & Body: My Off-Duty Explorations.",
    "section": "",
    "text": "I am a proud owner of 90’s vintage road bike. It was recently refurbished and looks smashing! It even has chipset print and binary code on the handles (photo pre-renovation)!"
  },
  {
    "objectID": "pages/hobbies.html#strolling.",
    "href": "pages/hobbies.html#strolling.",
    "title": "Fueling the Mind & Body: My Off-Duty Explorations.",
    "section": "",
    "text": "Yes, just strolling, but with a philosophy. No headphones, no distractions, no direction. Just observing what changed in the neighborhood I’ve lived in for the last 15 years, and what is happening inside. Think awareness meditation but while walking."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "bwrob blog",
    "section": "",
    "text": "This blog is a battleground of sorts, but instead of swords and shields, we wield the weapons of Python and C++. I’m a mathematician turned quantitative analyst turned software engineer. You can expect high standard deviation of topics here.\nHere, I’ll document my coding conquests, from building practical and impractical tools, exploring financial concepts, to playing around with physics simulations.\nExpect a healthy dose of humor alongside the technical discussions. Let’s be honest, even the most complex problems are more enjoyable with a sprinkle of laughter. So, grab a cup of coffee and join me on this exploration – even if it’s just for one interested reader!\n\n\n\n\n\n\n\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nLinux in Windows via WSL\n\n\n\nDev setup\n\n\n\nGreat dev setup and still CS coffee break\n\n\n\nbwrob\n\n\nAug 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExit stack to the rescue\n\n\n\nPythonic Distractions\n\n\nContext Managers\n\n\n\nHow to chain resource managers in elegant way.\n\n\n\nbwrob\n\n\nMay 12, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nStrategies for Numerical Integration\n\n\n\nPythonic Distractions\n\n\nDesign Patterns\n\n\n\nHow to apply strategy design pattern to decouple integration problem from method it’s solved with.\n\n\n\nbwrob\n\n\nApr 28, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWelcome To My Blog\n\n\n\nNews\n\n\n\nWarm welcome to enjoy the ride with me.\n\n\n\nbwrob\n\n\nApr 23, 2024\n\n\n\n\n\n\n\n\nNo matching items\n\n Back to top"
  },
  {
    "objectID": "pages/resume.html",
    "href": "pages/resume.html",
    "title": "Bartosz Wróblewski",
    "section": "",
    "text": "Mathematician at heart, quantitative finance technologist by trade. I leverage diverse experiences in academia, derivatives valuation, market risk, and quantitative development to bring a generalist’s perspective to quantitative finance and software engineering.\n\n \n  \n   \n  \n    \n     LinkedIn\n  \n  \n    \n     Github\n  \n  \n    \n     Contact"
  },
  {
    "objectID": "pages/resume.html#professional-experience",
    "href": "pages/resume.html#professional-experience",
    "title": "Bartosz Wróblewski",
    "section": "Professional Experience",
    "text": "Professional Experience\n\nSyberry\n\nFinancial Software Engineer | Sep 2023 – Sep 2024\nDevelopment of a financial platform for a hedge fund client.\n\nQuantitative developer bridging the gap between hedge fund risk managers and software engineers.\nDeveloping risk management platform that pipes and transforms trading data.\nResponsible for integration of vendor risk management system into the platform, efficient orchestration of asynchronous API calls and resources.\nWorking directly with client’s risk manager and CRO on specifying the business needs and requirements.\n\nTechnologies\n\nBackend: Python, Dagster, FastAPI, Pytest, Pandas, NumPy, SQLAlchemy.\nDatabases: PostgreSQL, DuckDB.\nInfrastructure/pipelines: Amazon Web Services, Terraform, Terraspace, Docker, GitHub Actions.\n\n\n\n\nBank of New York Mellon\n\nSenior Specialist, Model Development | Jul 2022 – Sep 2023\nIndependent specialist at Risk and Compliance department (MO). Market Risk team responsible for modeling of VaR and SVaR, comprehensive test scenarios and portfolio sensitivity exposures.\n\nDeveloping and maintaining market risk models — VaR, SVaR — and stress testing frameworks implemented in C++.\nCalibrating and benchmarking vendor pricing models (Murex risk management system).\nDesigning, creating and analyzing risk-related reports and ad hoc analyses for front office and risk management.\nResponsible for Market Risk RWA projections submission for CCAR 2023.\nCoordinating development projects with IT, Validation and Risk Management.\nDeveloped a method for directly comparing interest rate sensitivities between FO and MO systems using different conventions and curves setups.\nRe-implemented legacy C++ volatility surface builder in Python without performance loss.\n\nTechnologies\n\nInternal risk models: C++.\nVendor pricing system: Murex.\nDatabases: MS SQL.\nTooling: Python, Quantlib, VBA.\n\n\n\n\nCredit Suisse\n\nQuantitative Analyst | Nov 2018 – Jun 2022\nJunior analyst at Credit Derivatives division, part of global front office QuantStrats department (700+ quants, developers and data analysts).\n\nDevelopment and maintenance of an in-house valuation framework used across bank’s systems (COM C++ and .Net). Contributions to valuation models and market data object builders used in pricing.\nProviding direct support to traders and Middle Office in ad hoc investigations on valuation, risks and technical issues.\nExtending and creating COM-addin-based Excel pricing sheets used by Trading and Product Control.\nAssisting with calculation and analysis of risk profiles, PnL reports, transition impact assessments of trade portfolios.\nRepresented the company by giving lectures and taking part in campus recruitment programs.\nCoordinated resolution of strategic process of calculating Collateral Adjusted Valuation for the xVA desk.\n\nStructured Notes\nCredit Suisse issued structured note products (corporate bonds with derivatives attached to payout).\n\nContributed to structured notes valuation model framework implemented in factorized C++.\nUpdated credit curve models and utilities to be compatible with OIS discounting in preparation to LIBOR cessation (F#).\nExtended trading pricing sheets with logic needed to price instruments with compounding rates financing (Excel, COM-addins, .Net extensions).\nCollaborated with quantitative developers from in-house risk management system project on addition of new market data builders (C#).\n\nLongevity Derivatives\nLongevity-based (insurance policies and pension schemes) financial derivatives.\n\nMigrated existing legacy tools to 64-bit environment.\nProvided technical support to Product Control in their monthly tie-in processes.\n\nTechnologies\n\nPricing framework: F#, C++, COM.\nRisk Managment: C#.\nTrading tools: Excel, VBA.\nCI/CD: Perforce, TeamCity."
  },
  {
    "objectID": "pages/resume.html#academic-experience",
    "href": "pages/resume.html#academic-experience",
    "title": "Bartosz Wróblewski",
    "section": "Academic Experience",
    "text": "Academic Experience\n\nUniversity of Wrocław\n\nPhD Candidate | Oct 2016 – Jan 2019\nResearched evolution equations involving non-local unbounded operators. Focused on applications of functional and harmonic analysis. Main ‘hero’ of my research was the fractional Laplacian operator — jump-diffusion analogue of the classical Laplacian.\nAlso interested in hydrodynamic models and applications of PDEs in physics (porous medium modelling, flocking models, quantum mechanics).\nUnfinished.\n\n\nJunior Researcher | Apr 2017 – Jan 2019\nParticipated in the Polish National Science Center research grant Nonlocal parabolic problems: regularity, blowup, pattern formation. Principal Investigator Prof. Piotr Biler.\n\n\nTeaching Assistant | Mar 2017 – Jul 2018\nNon-linear Functional Analysis, Ordinary Differential Equations, Honors Ordinary Differential Equations.\n\n\n\nUniversity of Warsaw\n\nResearch Intern | Dec 2016 – Mar 2017\nVisiting position during CrossFields PDEs semester organised and sponsored by The Simons Foundation.\nCollaboration with Raphael Dunchin, Piotr B. Mucha and with Jan Peszek in the research on fractional Euler alignment system (hydrodynamic flocking dynamics).\n\nRegular solutions to the fractional Euler alignment system in the Besov spaces framework published in Mathematical Models and Methods in Applied Sciences Vol. 29, No. 01, pp. 89-119\n\n\n\nTeaching Assistant | Jan 2017 – Mar 2017\nAnalysis 1, Analysis 2."
  },
  {
    "objectID": "pages/resume.html#education",
    "href": "pages/resume.html#education",
    "title": "Bartosz Wróblewski",
    "section": "Education",
    "text": "Education\n\nUniversity of Wrocław\n\nMsc in Theoretical Mathematics | Oct 2014 – Sep 2016\nThesis topic: “The anomalous diffusion and fractional Laplacian on the half-line” written under the supervision of Prof. Grzegorz Karch.\n\n\n\nWrocław University of Science and Technology\n\nBSc in Theoretical Mathematics | Oct 2011 – Jul 2014"
  },
  {
    "objectID": "posts/linux_in_windows/index.html#windows-linux-and-you-ménage-à-trois",
    "href": "posts/linux_in_windows/index.html#windows-linux-and-you-ménage-à-trois",
    "title": "Linux in Windows via WSL",
    "section": "Windows, Linux, and You: Ménage à trois",
    "text": "Windows, Linux, and You: Ménage à trois\nTired of the same old Windows vs. Linux beef among PC superusers? Well, get ready to become a mediator in this feud. I’ll show you how to get the best of both worlds.\n\nPros and cons\nWindows OS has long been the dominant platform for mainstream consumers and businesses. It offers good hardware compatibility, de facto the PC gaming experience and is friendly to the casual user. However, Windows has significant limitations in terms of system control and software development tools.\nLinux, on the other hand, is an operating system created by developers and for developers (and system administrators). It provides infinite flexibility and a deep pool of open-source tools. But the learning curve is steep, the open-source projects often get abandoned and with great power (sudo) comes great responsibility (and sometimes system reinstall).\n\n\n\n\n\n\nNote\n\n\n\nActually, to publish this post in the most convenient and elegant way, I needed to switch to Linux. The Windows quarto CLI fails with some certification errors, coming from deno, that I can’t be bothered to clean up. Discovered this while writing these words as my previous approach was much messier. Irony is the ambrosia of life (for me at least).\n\n\n\n\nBridging the gap\nAt this point even Microsoft — a strong contrarian to Linux in the past — embraced the usefulness of Linux shell at your fingertips. Imagine having the familiar interface of Windows for your everyday tasks. Combine it with a the raw power and controllability of Linux for when you need to dive deep into development or system administration. And limited stakes once you (inevitably) remove half of your file system with a bash script. Enter Windows Subsystem for Linux (WSL): a ticket to 10x-ing your software development on Windows.\n\n\nWSL vs. Virtual Machines: What’s the Difference?\nYou might be wondering how WSL differs from a traditional virtual machine (VM). While both provide a way to run Linux on Windows, they operate in different ways. A VM emulates a virtual computer within your computer, complete with its own operating system and make-belive hardware resources. This makes VMs resource-intensive and can impact overall system performance. They are also hard to set up and maintain.\nWSL, on the other hand, is a more lightweight approach. It integrates Linux directly into the Windows kernel, allowing for faster boot times, better performance, and seamless file sharing between Windows and Linux environments."
  },
  {
    "objectID": "posts/linux_in_windows/index.html#installing-and-setting-up-wsl",
    "href": "posts/linux_in_windows/index.html#installing-and-setting-up-wsl",
    "title": "Linux in Windows via WSL",
    "section": "Installing and setting up WSL",
    "text": "Installing and setting up WSL\nFirst, we need to set up the WSL and install a chosen Linux distribution. Fortunately, this is “super easy, barely an inconvenience”. You can choose from a list of distros pre-packaged by Microsoft or download and build an image from scratch. You can even build Arch and be legally allowed to say BTW, I use Arch (on Windows). For this guide, we’ll take a more conventional approach and opt for the long-term support (LTS) version of Ubuntu. Now, open the Powershell with administrative privileges and run:\nwsl --update\nwsl --version\nThese commands ensure that WSL is up-to-date and displays the installed WSL version.\n\nOur next command will be:\nwsl -l -o\nThis yields a curated list of pre-packaged Linux distributions that Microsoft provides, making the process almost effortless.\n\nFor the installation itself:\nwsl --install -d 'Ubuntu-24.04'\n\nReboot the Windows system and you’ll see `Ubuntu’ among your applications."
  },
  {
    "objectID": "posts/linux_in_windows/index.html#base-setup-new-shell-and-package-manager",
    "href": "posts/linux_in_windows/index.html#base-setup-new-shell-and-package-manager",
    "title": "Linux in Windows via WSL",
    "section": "Base setup — new shell and package manager",
    "text": "Base setup — new shell and package manager\nThere is an additional benefit we can reap with just a bit of more work — a fully system-agnostic setup. By having Linux kernel run on Windows, we unified 2 out of 3 giants. The only pillar that is missing is the Mac OS. But wait, it’s based on Unix as well! It just uses different default shell and lacks a package manager, as Apple doesn’t trust its clients. zsh offers a more interactive and customizable shell experience compared to the default bash. Homebrew, often referred to as the “missing package manager for macOS”, provides a convenient way to install additional software on Linux systems. Let’s change the terminal shell to zsh in our Ubuntu installation and compile a secondary (to apt-get) package manager – brew.\n\nBrewing starts\nBefore we dive into installing Homebrew, we need to equip our system with the essential tools. The build-essential package provides a collection of compilers and libraries necessary for building software from the source code. Git is a version control system used for managing code projects.\nLet’s install these prerequisites using the following command:\nsudo apt-get upgrade -y\nsudo apt-get install build-essential git -y\nExecute the installation script for Homebrew:\nINSTALL_PATH=\"https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh\"\n/bin/bash -c \"$(curl -fsSL $INSTALL_PATH)\"\n\nTo make Homebrew accessible from your shell, you need to load its environment variables. The following command achieves this and subsequently runs a diagnostic check:\neval \"$(/home/linuxbrew/.linuxbrew/bin/brew shellenv)\"\nbrew doctor\n\nDoctor’s orders to append brew to some set of paths! Let’s do this then:\necho 'export XDG_DATA_DIRS=\"/home/linuxbrew/.linuxbrew/share:$XDG_DATA_DIRS\"' &gt;&gt; ~/.profile"
  },
  {
    "objectID": "posts/linux_in_windows/index.html#z-shell-sea-shell",
    "href": "posts/linux_in_windows/index.html#z-shell-sea-shell",
    "title": "Linux in Windows via WSL",
    "section": "Z-shell — sea-shell",
    "text": "Z-shell — sea-shell\nHomebrew makes package management a breeze. Let’s install zsh, a powerful and customizable shell.\nbrew install zsh\nzsh --version\nzsh\nThis will take you to interactive .zshrc file setup. The file contains commands that are run each time a shell is spawned. You can either generate empty file with 0 or go through the interactive setup with 1. \nAdd the brew initialization to .zshrc file as well. This way brew will always be by your side!\n(echo; echo 'eval \"$(/home/linuxbrew/.linuxbrew/bin/brew shellenv)\"') &gt;&gt; /home/bwrob/.zshrc\nCheck the default shell and set it to zsh:\necho $SHELL\nsudo chsh -s $(which zsh)\necho $SHELL"
  },
  {
    "objectID": "posts/linux_in_windows/index.html#github-command-line-tool",
    "href": "posts/linux_in_windows/index.html#github-command-line-tool",
    "title": "Linux in Windows via WSL",
    "section": "GitHub command line tool",
    "text": "GitHub command line tool\nRemember git != GitHub, we need a way to authenticate and use Github from CLI. There’s a tool for that!\nbrew install gh\ngh auth login\n\nNow create a convenient directory and copy your favourite GitHub repo:\nmkdir repos && cd repos\ngh repo clone python_playground"
  },
  {
    "objectID": "posts/linux_in_windows/index.html#connect-to-visual-studio-code",
    "href": "posts/linux_in_windows/index.html#connect-to-visual-studio-code",
    "title": "Linux in Windows via WSL",
    "section": "Connect to Visual Studio Code",
    "text": "Connect to Visual Studio Code\nWhile WSL grants us the power of Linux, let’s not forget the user-friendly interface of Windows. When it comes to software development, we can achieve the perfect blend by integrating Visual Studio Code (VSC) with our WSL environment.\nHere’s how:\n\nInstall the WSL Extension in VSC: Fire up VSC on your Windows machine and head over to the Extensions tab. Search for “WSL” and install the official extension by Microsoft: WSL extension.\nLaunching VSC from WSL: Within your WSL terminal, you can directly invoke VSC as if it were running natively on Windows. Use the following command:\n\ncode ~\\repos\\python_playground\n\nIn the next post I will show you how to set up Python environment in Linux. Stay tuned :) .\n\n\n\n\n\n\nNote\n\n\n\nDownload the Ubuntu shell script here."
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in the bwrob blog. Welcome!\nThis blog is a battleground of sorts, but instead of swords and shields, we wield the weapons of Python and C++. I’m a mathematician turned quantitative analyst turned software engineer. You can expect high standard deviation of topics here.\nHere, I’ll document my coding conquests, from building practical and impractical tools, exploring financial concepts, to playing around with physics simulations.\nExpect a healthy dose of humor alongside the technical discussions. Let’s be honest, even the most complex problems are more enjoyable with a sprinkle of laughter. So, grab a cup of coffee and join me on this exploration – even if it’s just for one interested reader!\n\n\n\n Back to top"
  }
]